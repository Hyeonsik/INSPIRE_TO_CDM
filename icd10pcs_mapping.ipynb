{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f0c9521c-9a99-4e48-95d0-6c9826b3fb1b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-10-30T06:54:12.436536Z",
     "iopub.status.busy": "2023-10-30T06:54:12.436128Z",
     "iopub.status.idle": "2023-10-30T06:55:37.484898Z",
     "shell.execute_reply": "2023-10-30T06:55:37.483576Z",
     "shell.execute_reply.started": "2023-10-30T06:54:12.436501Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/anaconda-3-2020.02/envs/hskim/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting keras_nlp\n",
      "  Downloading keras_nlp-0.6.1-py3-none-any.whl (573 kB)\n",
      "     |████████████████████████████████| 573 kB 10.7 MB/s            \n",
      "\u001b[?25hCollecting keras-core\n",
      "  Downloading keras_core-0.1.5-py3-none-any.whl (924 kB)\n",
      "     |████████████████████████████████| 924 kB 16.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/hskim1/.local/lib/python3.8/site-packages (from keras_nlp) (1.24.4)\n",
      "Collecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "     |████████████████████████████████| 6.5 MB 16.9 MB/s            \n",
      "\u001b[?25hCollecting absl-py\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "     |████████████████████████████████| 130 kB 12.9 MB/s            \n",
      "\u001b[?25hCollecting rich\n",
      "  Downloading rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "     |████████████████████████████████| 239 kB 16.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/hskim1/.local/lib/python3.8/site-packages (from keras_nlp) (23.1)\n",
      "Collecting regex\n",
      "  Downloading regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "     |████████████████████████████████| 776 kB 15.5 MB/s            \n",
      "\u001b[?25hCollecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 15.8 MB/s            \n",
      "\u001b[?25hCollecting h5py\n",
      "  Downloading h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     |████████████████████████████████| 4.8 MB 16.2 MB/s            \n",
      "\u001b[?25hCollecting namex\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Using cached Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/hskim1/.local/lib/python3.8/site-packages (from rich->keras_nlp) (4.8.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     |████████████████████████████████| 87 kB 11.1 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-hub>=0.8.0\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "     |████████████████████████████████| 85 kB 7.1 MB/s             \n",
      "\u001b[?25hCollecting tensorflow<2.14,>=2.13.0\n",
      "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
      "     |████████████████████████████████| 479.6 MB 29 kB/s              \n",
      "\u001b[?25hCollecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "     |████████████████████████████████| 440 kB 17.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (58.5.3)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.24.4-cp37-abi3-manylinux2014_x86_64.whl (311 kB)\n",
      "     |████████████████████████████████| 311 kB 15.7 MB/s            \n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting typing-extensions<5.0,>=4.0.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 17.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (1.15.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "     |████████████████████████████████| 22.9 MB 421 kB/s             \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "     |████████████████████████████████| 5.3 MB 15.7 MB/s            \n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 16.2 MB/s            \n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "     |████████████████████████████████| 17.3 MB 11.8 MB/s            \n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 7.4 MB/s             \n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 3.4 MB/s              \n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     |████████████████████████████████| 2.4 MB 16.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (1.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (2.31.0)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "     |████████████████████████████████| 226 kB 18.6 MB/s            \n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "     |████████████████████████████████| 182 kB 16.5 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "     |████████████████████████████████| 6.6 MB 15.6 MB/s            \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "     |████████████████████████████████| 101 kB 13.2 MB/s           \n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (0.2.1)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/hskim1/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (6.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskim1/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (2019.11.28)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text->keras_nlp) (0.4.2)\n",
      "Installing collected packages: rsa, cachetools, requests-oauthlib, MarkupSafe, google-auth, werkzeug, tensorboard-data-server, protobuf, numpy, mdurl, markdown, grpcio, google-auth-oauthlib, absl-py, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, pygments, opt-einsum, markdown-it-py, libclang, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow-hub, tensorflow, rich, namex, dm-tree, tensorflow-text, regex, keras-core, keras-nlp\n",
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.4\n",
      "    Uninstalling numpy-1.24.4:\n",
      "      Successfully uninstalled numpy-1.24.4\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script markdown_py is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script google-oauthlib-tool is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.8.0\n",
      "    Uninstalling typing-extensions-4.8.0:\n",
      "      Successfully uninstalled typing-extensions-4.8.0\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script pygmentize is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script markdown-it is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbclassic 0.3.4 requires jupyter-server~=1.8, but you have jupyter-server 2.8.0 which is incompatible.\u001b[0m\n",
      "Successfully installed MarkupSafe-2.1.3 absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.2 dm-tree-0.1.8 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 keras-2.13.1 keras-core-0.1.5 keras-nlp-0.6.1 libclang-16.0.6 markdown-3.5 markdown-it-py-3.0.0 mdurl-0.1.2 namex-0.0.7 numpy-1.24.3 opt-einsum-3.3.0 protobuf-4.24.4 pygments-2.16.1 regex-2023.10.3 requests-oauthlib-1.3.1 rich-13.6.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-hub-0.15.0 tensorflow-io-gcs-filesystem-0.34.0 tensorflow-text-2.13.0 termcolor-2.3.0 typing-extensions-4.5.0 werkzeug-3.0.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d4fef663-74bb-47ac-85aa-3f064de59267",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-10-30T06:57:33.709767Z",
     "iopub.status.busy": "2023-10-30T06:57:33.709407Z",
     "iopub.status.idle": "2023-10-30T06:57:35.360550Z",
     "shell.execute_reply": "2023-10-30T06:57:35.359216Z",
     "shell.execute_reply.started": "2023-10-30T06:57:33.709730Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/anaconda-3-2020.02/envs/hskim/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-text in /home/hskim1/.local/lib/python3.8/site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow-text) (0.15.0)\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow-text) (2.13.1)\n",
      "Requirement already satisfied: packaging in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.5.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.34.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (4.24.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.14.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (23.5.26)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (1.59.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (2.13.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (58.5.3)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text) (16.0.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.34.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.23.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/hskim1/.local/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/hskim1/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/hskim1/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (5.3.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/hskim1/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/hskim1/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (6.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskim1/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/hskim1/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text) (0.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1741c3c3-88b5-4cd6-8a55-ff4e886196ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:05:25.730030Z",
     "iopub.status.busy": "2023-11-17T06:05:25.729674Z",
     "iopub.status.idle": "2023-11-17T06:05:42.744292Z",
     "shell.execute_reply": "2023-11-17T06:05:42.743175Z",
     "shell.execute_reply.started": "2023-11-17T06:05:25.729994Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:05:28.714313: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 15:05:33.430490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "#import sys\n",
    "#sys.path.append('./.local/lib/python3.8/site-packages')\n",
    "#sys.path.append('/usr/lib/python3/dist-packages')\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import Tokenizer, one_hot, text_to_word_sequence\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras_nlp.tokenizers import WordPieceTokenizer\n",
    "from keras.models import model_from_json\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCH = 100\n",
    "\n",
    "GPU = 3\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= f\"{GPU}\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0263ad-bf22-488f-a21c-71f120521e03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:05:42.746454Z",
     "iopub.status.busy": "2023-11-17T06:05:42.745917Z",
     "iopub.status.idle": "2023-11-17T06:06:16.675258Z",
     "shell.execute_reply": "2023-11-17T06:06:16.674249Z",
     "shell.execute_reply.started": "2023-11-17T06:05:42.746420Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1364053/1335861446.py:6: DtypeWarning: Columns (5,6,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_concept = pd.read_csv(f'vocab/CONCEPT.csv', sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "df_vocab = pd.read_csv(f'vocab/VOCABULARY.csv', sep='\\t', on_bad_lines='error')\n",
    "df_concept_rel = pd.read_csv(f'vocab/CONCEPT_RELATIONSHIP.csv', sep='\\t', on_bad_lines='error')\n",
    "df_concept = pd.read_csv(f'vocab/CONCEPT.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1887c03d-a85a-4a56-b602-52355ecc207b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:06:16.676385Z",
     "iopub.status.busy": "2023-11-17T06:06:16.676222Z",
     "iopub.status.idle": "2023-11-17T06:06:16.687243Z",
     "shell.execute_reply": "2023-11-17T06:06:16.686351Z",
     "shell.execute_reply.started": "2023-11-17T06:06:16.676369Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, droprate):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.droprate = droprate\n",
    "        self.ff_dim = ff_dim\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(droprate)\n",
    "        self.dropout2 = layers.Dropout(droprate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'embed_dim': self.embed_dim, 'num_heads': self.num_heads, 'ff_dim':ff_dim, 'droprate':self.droprate}\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'maxlen': self.maxlen, 'vocab_size': self.vocab_size, 'embed_dim': self.embed_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c062dad-9616-4d31-89a8-6682fe79d1e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:06:16.688981Z",
     "iopub.status.busy": "2023-11-17T06:06:16.688737Z",
     "iopub.status.idle": "2023-11-17T06:06:18.398332Z",
     "shell.execute_reply": "2023-11-17T06:06:18.397339Z",
     "shell.execute_reply.started": "2023-11-17T06:06:16.688957Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CDC master\n",
    "# https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fwww.cdc.gov%2Fnhsn%2Fxls%2Ficd10-pcs-pcm-nhsn-opc.xlsx&wdOrigin=BROWSELINK\n",
    "input_path = 'icd10pcs_mapping'\n",
    "df1 = pd.read_csv(f'{input_path}/icd10-pcs-pcm-nhsn-opc.csv', dtype=str)\n",
    "df1.rename(columns={'ICD-10-PCS Codes':'code', 'Procedure Code Descriptions':'name'}, inplace=True)\n",
    "df1['code'] = df1['code'].str[:-1]   # remove empty space in the end part of code\n",
    "df1['src'] = 'cdc'\n",
    "\n",
    "# Centers for Medicare & Medicaid Services\n",
    "# https://www.cms.gov/medicare/icd-10/2022-icd-10-pcs\n",
    "df2 = pd.read_fwf(f'{input_path}/icd10pcs_order_2022.txt', widths=(6,7,3,60), header=None, dtype=str)\n",
    "df2.rename(columns={1:'code',3:'name'}, inplace=True)\n",
    "df2['src'] = 'cms'\n",
    "\n",
    "# SNUH data\n",
    "# system, operation, body part, approach\n",
    "#df3 = pd.read_csv('icd10_mapping_with_final.csv', dtype=str)\n",
    "df3 = pd.read_csv(f'{input_path}/icd10_mapping_hclee.csv', usecols=['opid', 'p', 'o', 'a', 'opname'], dtype=str)  # the label manually checked by hclee\n",
    "#df3.loc[df3['opname_final'] == df3['opname'], 'opname_final'] = ''\n",
    "# merge the name with opname and opname_final\n",
    "df3['name'] = df3['opname']\n",
    "#df3['name'] = None\n",
    "#df3.loc[df3['opname'].notnull() & df3['opname_final'].notnull(), 'name'] = df3['opname'] + '\\r' + df3['opname_final']\n",
    "#df3.loc[df3['opname'].notnull() & df3['opname_final'].isnull(), 'name'] = df3['opname']\n",
    "#df3.loc[df3['opname'].isnull() & df3['opname_final'].notnull(), 'name'] = df3['opname_final']\n",
    "df3['src'] = 'snuh'\n",
    "\n",
    "# MIMIC\n",
    "df4 = pd.read_csv(f'{input_path}/d_icd_procedures.csv.gz', compression='gzip')\n",
    "df4.rename(columns={'icd_code':'code','long_title':'name'}, inplace=True)\n",
    "df4 = df4[df4['icd_version'] == 10]\n",
    "df4['src'] = 'mimic'\n",
    "\n",
    "# merge all\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "\n",
    "# remove the row without op name\n",
    "df.dropna(subset='name', inplace=True)\n",
    "\n",
    "# split the part from the icd code for mimic, cdc, and cms\n",
    "df.loc[df['code'].str.len() < 5, 'code'] = None\n",
    "df.loc[df['code'].str[0] != '0', 'code'] = None\n",
    "null_mask = df['p'].isnull()\n",
    "df.loc[null_mask, 'p'] = df.loc[null_mask, 'code'].str[1] + df.loc[null_mask, 'code'].str[3]\n",
    "null_mask = df['o'].isnull()\n",
    "df.loc[null_mask, 'o'] = df.loc[null_mask, 'code'].str[2] #+ df.loc[null_mask, 'code'].str[2]\n",
    "null_mask = df['a'].isnull()\n",
    "df.loc[null_mask, 'a'] = df.loc[null_mask, 'code'].str[4] #+ df.loc[null_mask, 'code'].str[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "98ef866a-d5ff-48fc-af4a-c7b8a373a797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T06:42:45.759905Z",
     "iopub.status.busy": "2023-10-30T06:42:45.759460Z",
     "iopub.status.idle": "2023-10-30T06:42:45.790269Z",
     "shell.execute_reply": "2023-10-30T06:42:45.789517Z",
     "shell.execute_reply.started": "2023-10-30T06:42:45.759868Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286215, 9999, 8045, 4991)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df3), df3['p'].isna().sum(), df3['o'].isna().sum(), df3['a'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb9b4d-abfc-4925-bba1-21c3b981c980",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### eda - SNOMED- relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8f712ca6-8d7e-477c-8c0a-ca9d8bacddba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:06:51.036282Z",
     "iopub.status.busy": "2023-11-02T17:06:51.035877Z",
     "iopub.status.idle": "2023-11-02T17:06:52.073338Z",
     "shell.execute_reply": "2023-11-02T17:06:52.072502Z",
     "shell.execute_reply.started": "2023-11-02T17:06:51.036247Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>vocabulary_id</th>\n",
       "      <th>concept_class_id</th>\n",
       "      <th>standard_concept</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6903267</th>\n",
       "      <td>4001100</td>\n",
       "      <td>Resection of stomach fundus</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>10002003</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903439</th>\n",
       "      <td>4002094</td>\n",
       "      <td>Repair of retinal detachment with xenon arc ph...</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>10006000</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903573</th>\n",
       "      <td>40264452</td>\n",
       "      <td>Retired procedure</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10009007</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20020131</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903613</th>\n",
       "      <td>4000799</td>\n",
       "      <td>Cauterization of Bartholin's gland</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>1001000</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6903617</th>\n",
       "      <td>42534812</td>\n",
       "      <td>Ultrasonography of calf of right lower leg</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>1001000087107</td>\n",
       "      <td>20180131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957113</th>\n",
       "      <td>40648609</td>\n",
       "      <td>Fitting of prosthesis or prosthetic device of arm</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9987003</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20070131</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957156</th>\n",
       "      <td>4321416</td>\n",
       "      <td>Computed tomography oblique</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9988008</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957419</th>\n",
       "      <td>4322524</td>\n",
       "      <td>Radiation therapy treatment planning service</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9990009</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957800</th>\n",
       "      <td>4322532</td>\n",
       "      <td>Incision of diaphragm</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9993006</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957933</th>\n",
       "      <td>4323161</td>\n",
       "      <td>Arthrotomy with drainage of tarsometatarsal joint</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9996003</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90499 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         concept_id                                       concept_name  \\\n",
       "6903267     4001100                        Resection of stomach fundus   \n",
       "6903439     4002094  Repair of retinal detachment with xenon arc ph...   \n",
       "6903573    40264452                                  Retired procedure   \n",
       "6903613     4000799                 Cauterization of Bartholin's gland   \n",
       "6903617    42534812         Ultrasonography of calf of right lower leg   \n",
       "...             ...                                                ...   \n",
       "7957113    40648609  Fitting of prosthesis or prosthetic device of arm   \n",
       "7957156     4321416                        Computed tomography oblique   \n",
       "7957419     4322524       Radiation therapy treatment planning service   \n",
       "7957800     4322532                              Incision of diaphragm   \n",
       "7957933     4323161  Arthrotomy with drainage of tarsometatarsal joint   \n",
       "\n",
       "         domain_id vocabulary_id concept_class_id standard_concept  \\\n",
       "6903267  Procedure        SNOMED        Procedure                S   \n",
       "6903439  Procedure        SNOMED        Procedure                S   \n",
       "6903573  Procedure        SNOMED        Procedure              NaN   \n",
       "6903613  Procedure        SNOMED        Procedure                S   \n",
       "6903617  Procedure        SNOMED        Procedure                S   \n",
       "...            ...           ...              ...              ...   \n",
       "7957113  Procedure        SNOMED        Procedure              NaN   \n",
       "7957156  Procedure        SNOMED        Procedure                S   \n",
       "7957419  Procedure        SNOMED        Procedure                S   \n",
       "7957800  Procedure        SNOMED        Procedure                S   \n",
       "7957933  Procedure        SNOMED        Procedure                S   \n",
       "\n",
       "          concept_code  valid_start_date  valid_end_date invalid_reason  \n",
       "6903267       10002003          20020131        20991231            NaN  \n",
       "6903439       10006000          20020131        20991231            NaN  \n",
       "6903573       10009007          19700101        20020131              D  \n",
       "6903613        1001000          20020131        20991231            NaN  \n",
       "6903617  1001000087107          20180131        20991231            NaN  \n",
       "...                ...               ...             ...            ...  \n",
       "7957113        9987003          20020131        20070131              D  \n",
       "7957156        9988008          20020131        20991231            NaN  \n",
       "7957419        9990009          20020131        20991231            NaN  \n",
       "7957800        9993006          20020131        20991231            NaN  \n",
       "7957933        9996003          20020131        20991231            NaN  \n",
       "\n",
       "[90499 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snomed_vocabs = df_concept[(df_concept['vocabulary_id']=='SNOMED') & (df_concept['domain_id']=='Procedure')]\n",
    "snomed_vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b4f10d9-cb89-4013-9a61-22b79dfe65d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T15:42:54.858128Z",
     "iopub.status.busy": "2023-11-02T15:42:54.857161Z",
     "iopub.status.idle": "2023-11-02T15:42:55.349061Z",
     "shell.execute_reply": "2023-11-02T15:42:55.348152Z",
     "shell.execute_reply.started": "2023-11-02T15:42:54.858082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "icd10pcs_ids = df_concept.loc[df_concept['vocabulary_id']=='ICD10PCS', 'concept_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "426eb328-ef8e-43d0-a8e0-226b84f29a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T16:43:18.655635Z",
     "iopub.status.busy": "2023-11-02T16:43:18.655223Z",
     "iopub.status.idle": "2023-11-02T16:43:18.666216Z",
     "shell.execute_reply": "2023-11-02T16:43:18.665560Z",
     "shell.execute_reply.started": "2023-11-02T16:43:18.655599Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [x, y]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p = pd.DataFrame(columns=['x', 'y'])\n",
    "df_o = pd.DataFrame(columns=['x', 'y'])\n",
    "df_a = pd.DataFrame(columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74c402b1-572b-4866-9ebb-2a34503137cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:05:49.404021Z",
     "iopub.status.busy": "2023-11-02T17:05:49.403615Z",
     "iopub.status.idle": "2023-11-02T17:05:49.411549Z",
     "shell.execute_reply": "2023-11-02T17:05:49.410590Z",
     "shell.execute_reply.started": "2023-11-02T17:05:49.403986Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept_id                      4000935\n",
       "concept_name                   BITTER-3\n",
       "domain_id                          Drug\n",
       "vocabulary_id                    SNOMED\n",
       "concept_class_id    Pharma/Biol Product\n",
       "standard_concept                    NaN\n",
       "concept_code                  100000000\n",
       "valid_start_date               20020131\n",
       "valid_end_date                 20090731\n",
       "invalid_reason                        D\n",
       "Name: 6903171, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71e26364-ebab-4127-8118-1ebfb5c87e96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:07:06.838919Z",
     "iopub.status.busy": "2023-11-02T17:07:06.838506Z",
     "iopub.status.idle": "2023-11-02T17:07:07.437193Z",
     "shell.execute_reply": "2023-11-02T17:07:07.436357Z",
     "shell.execute_reply.started": "2023-11-02T17:07:06.838884Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id_1</th>\n",
       "      <th>concept_id_2</th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909558</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40642537</td>\n",
       "      <td>Has status</td>\n",
       "      <td>20220128</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909559</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40642539</td>\n",
       "      <td>Has Module</td>\n",
       "      <td>20220128</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413121</th>\n",
       "      <td>4001100</td>\n",
       "      <td>3397873</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413122</th>\n",
       "      <td>4001100</td>\n",
       "      <td>4001100</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413123</th>\n",
       "      <td>4001100</td>\n",
       "      <td>4001100</td>\n",
       "      <td>Maps to</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413124</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40314079</td>\n",
       "      <td>Concept same_as from</td>\n",
       "      <td>20140401</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413125</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40314079</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14388908</th>\n",
       "      <td>4001100</td>\n",
       "      <td>4185453</td>\n",
       "      <td>Has dir proc site</td>\n",
       "      <td>20110731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21042977</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40368774</td>\n",
       "      <td>Concept same_as from</td>\n",
       "      <td>20140401</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21042978</th>\n",
       "      <td>4001100</td>\n",
       "      <td>40368774</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41086649</th>\n",
       "      <td>4001100</td>\n",
       "      <td>3100933</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41086650</th>\n",
       "      <td>4001100</td>\n",
       "      <td>3145447</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41086651</th>\n",
       "      <td>4001100</td>\n",
       "      <td>4021544</td>\n",
       "      <td>Is a</td>\n",
       "      <td>20110731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54331450</th>\n",
       "      <td>4001100</td>\n",
       "      <td>4044525</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20110731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54331451</th>\n",
       "      <td>4001100</td>\n",
       "      <td>45532562</td>\n",
       "      <td>Mapped from</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          concept_id_1  concept_id_2       relationship_id  valid_start_date  \\\n",
       "1909558        4001100      40642537            Has status          20220128   \n",
       "1909559        4001100      40642539            Has Module          20220128   \n",
       "2413121        4001100       3397873           Mapped from          19700101   \n",
       "2413122        4001100       4001100           Mapped from          19700101   \n",
       "2413123        4001100       4001100               Maps to          19700101   \n",
       "2413124        4001100      40314079  Concept same_as from          20140401   \n",
       "2413125        4001100      40314079           Mapped from          19700101   \n",
       "14388908       4001100       4185453     Has dir proc site          20110731   \n",
       "21042977       4001100      40368774  Concept same_as from          20140401   \n",
       "21042978       4001100      40368774           Mapped from          19700101   \n",
       "41086649       4001100       3100933           Mapped from          19700101   \n",
       "41086650       4001100       3145447           Mapped from          19700101   \n",
       "41086651       4001100       4021544                  Is a          20110731   \n",
       "54331450       4001100       4044525            Has method          20110731   \n",
       "54331451       4001100      45532562           Mapped from          19700101   \n",
       "\n",
       "          valid_end_date  invalid_reason  \n",
       "1909558         20991231             NaN  \n",
       "1909559         20991231             NaN  \n",
       "2413121         20991231             NaN  \n",
       "2413122         20991231             NaN  \n",
       "2413123         20991231             NaN  \n",
       "2413124         20991231             NaN  \n",
       "2413125         20991231             NaN  \n",
       "14388908        20991231             NaN  \n",
       "21042977        20991231             NaN  \n",
       "21042978        20991231             NaN  \n",
       "41086649        20991231             NaN  \n",
       "41086650        20991231             NaN  \n",
       "41086651        20991231             NaN  \n",
       "54331450        20991231             NaN  \n",
       "54331451        20991231             NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concept_rel[df_concept_rel['concept_id_1']==row['concept_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d30b517-eb79-4c1d-9684-b60c154b47fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:14:21.864305Z",
     "iopub.status.busy": "2023-11-02T17:14:21.863882Z",
     "iopub.status.idle": "2023-11-02T17:14:21.870349Z",
     "shell.execute_reply": "2023-11-02T17:14:21.869522Z",
     "shell.execute_reply.started": "2023-11-02T17:14:21.864270Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "928d93a5-585e-47f6-a9f3-d8209fa72fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:14:36.305069Z",
     "iopub.status.busy": "2023-11-02T17:14:36.304671Z",
     "iopub.status.idle": "2023-11-02T17:14:41.141418Z",
     "shell.execute_reply": "2023-11-02T17:14:41.140466Z",
     "shell.execute_reply.started": "2023-11-02T17:14:36.305035Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_match = snomed_vocabs.merge(df_concept_rel[(df_concept_rel['relationship_id']=='Subsumes')], left_on='concept_id', right_on='concept_id_1', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5dab3c3d-dd8d-4f8d-8a29-a2ad7b258f29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:15:56.254550Z",
     "iopub.status.busy": "2023-11-02T17:15:56.254113Z",
     "iopub.status.idle": "2023-11-02T17:15:56.263496Z",
     "shell.execute_reply": "2023-11-02T17:15:56.262509Z",
     "shell.execute_reply.started": "2023-11-02T17:15:56.254514Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333249"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~df_match['concept_id_2'].isna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9bd17d5-97d3-4d6f-82e3-853d68c4a72b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:14:58.489255Z",
     "iopub.status.busy": "2023-11-02T17:14:58.488843Z",
     "iopub.status.idle": "2023-11-02T17:14:58.510187Z",
     "shell.execute_reply": "2023-11-02T17:14:58.509550Z",
     "shell.execute_reply.started": "2023-11-02T17:14:58.489219Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>vocabulary_id</th>\n",
       "      <th>concept_class_id</th>\n",
       "      <th>standard_concept</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>valid_start_date_x</th>\n",
       "      <th>valid_end_date_x</th>\n",
       "      <th>invalid_reason_x</th>\n",
       "      <th>concept_id_1</th>\n",
       "      <th>concept_id_2</th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>valid_start_date_y</th>\n",
       "      <th>valid_end_date_y</th>\n",
       "      <th>invalid_reason_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4001100</td>\n",
       "      <td>Resection of stomach fundus</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>10002003</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4002094</td>\n",
       "      <td>Repair of retinal detachment with xenon arc ph...</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>10006000</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40264452</td>\n",
       "      <td>Retired procedure</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10009007</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20020131</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4000799</td>\n",
       "      <td>Cauterization of Bartholin's gland</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>1001000</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42534812</td>\n",
       "      <td>Ultrasonography of calf of right lower leg</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>1001000087107</td>\n",
       "      <td>20180131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42534812.0</td>\n",
       "      <td>42538953.0</td>\n",
       "      <td>Subsumes</td>\n",
       "      <td>20180131.0</td>\n",
       "      <td>20991231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403577</th>\n",
       "      <td>4322524</td>\n",
       "      <td>Radiation therapy treatment planning service</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9990009</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4322524.0</td>\n",
       "      <td>4044940.0</td>\n",
       "      <td>Subsumes</td>\n",
       "      <td>20110731.0</td>\n",
       "      <td>20991231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403578</th>\n",
       "      <td>4322524</td>\n",
       "      <td>Radiation therapy treatment planning service</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9990009</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4322524.0</td>\n",
       "      <td>4061543.0</td>\n",
       "      <td>Subsumes</td>\n",
       "      <td>20110731.0</td>\n",
       "      <td>20991231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403579</th>\n",
       "      <td>4322524</td>\n",
       "      <td>Radiation therapy treatment planning service</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9990009</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4322524.0</td>\n",
       "      <td>4044943.0</td>\n",
       "      <td>Subsumes</td>\n",
       "      <td>20110731.0</td>\n",
       "      <td>20991231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403580</th>\n",
       "      <td>4322532</td>\n",
       "      <td>Incision of diaphragm</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9993006</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4322532.0</td>\n",
       "      <td>42535710.0</td>\n",
       "      <td>Subsumes</td>\n",
       "      <td>20180131.0</td>\n",
       "      <td>20991231.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403581</th>\n",
       "      <td>4323161</td>\n",
       "      <td>Arthrotomy with drainage of tarsometatarsal joint</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>SNOMED</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>S</td>\n",
       "      <td>9996003</td>\n",
       "      <td>20020131</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>403582 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        concept_id                                       concept_name  \\\n",
       "0          4001100                        Resection of stomach fundus   \n",
       "1          4002094  Repair of retinal detachment with xenon arc ph...   \n",
       "2         40264452                                  Retired procedure   \n",
       "3          4000799                 Cauterization of Bartholin's gland   \n",
       "4         42534812         Ultrasonography of calf of right lower leg   \n",
       "...            ...                                                ...   \n",
       "403577     4322524       Radiation therapy treatment planning service   \n",
       "403578     4322524       Radiation therapy treatment planning service   \n",
       "403579     4322524       Radiation therapy treatment planning service   \n",
       "403580     4322532                              Incision of diaphragm   \n",
       "403581     4323161  Arthrotomy with drainage of tarsometatarsal joint   \n",
       "\n",
       "        domain_id vocabulary_id concept_class_id standard_concept  \\\n",
       "0       Procedure        SNOMED        Procedure                S   \n",
       "1       Procedure        SNOMED        Procedure                S   \n",
       "2       Procedure        SNOMED        Procedure              NaN   \n",
       "3       Procedure        SNOMED        Procedure                S   \n",
       "4       Procedure        SNOMED        Procedure                S   \n",
       "...           ...           ...              ...              ...   \n",
       "403577  Procedure        SNOMED        Procedure                S   \n",
       "403578  Procedure        SNOMED        Procedure                S   \n",
       "403579  Procedure        SNOMED        Procedure                S   \n",
       "403580  Procedure        SNOMED        Procedure                S   \n",
       "403581  Procedure        SNOMED        Procedure                S   \n",
       "\n",
       "         concept_code  valid_start_date_x  valid_end_date_x invalid_reason_x  \\\n",
       "0            10002003            20020131          20991231              NaN   \n",
       "1            10006000            20020131          20991231              NaN   \n",
       "2            10009007            19700101          20020131                D   \n",
       "3             1001000            20020131          20991231              NaN   \n",
       "4       1001000087107            20180131          20991231              NaN   \n",
       "...               ...                 ...               ...              ...   \n",
       "403577        9990009            20020131          20991231              NaN   \n",
       "403578        9990009            20020131          20991231              NaN   \n",
       "403579        9990009            20020131          20991231              NaN   \n",
       "403580        9993006            20020131          20991231              NaN   \n",
       "403581        9996003            20020131          20991231              NaN   \n",
       "\n",
       "        concept_id_1  concept_id_2 relationship_id  valid_start_date_y  \\\n",
       "0                NaN           NaN             NaN                 NaN   \n",
       "1                NaN           NaN             NaN                 NaN   \n",
       "2                NaN           NaN             NaN                 NaN   \n",
       "3                NaN           NaN             NaN                 NaN   \n",
       "4         42534812.0    42538953.0        Subsumes          20180131.0   \n",
       "...              ...           ...             ...                 ...   \n",
       "403577     4322524.0     4044940.0        Subsumes          20110731.0   \n",
       "403578     4322524.0     4061543.0        Subsumes          20110731.0   \n",
       "403579     4322524.0     4044943.0        Subsumes          20110731.0   \n",
       "403580     4322532.0    42535710.0        Subsumes          20180131.0   \n",
       "403581           NaN           NaN             NaN                 NaN   \n",
       "\n",
       "        valid_end_date_y  invalid_reason_y  \n",
       "0                    NaN               NaN  \n",
       "1                    NaN               NaN  \n",
       "2                    NaN               NaN  \n",
       "3                    NaN               NaN  \n",
       "4             20991231.0               NaN  \n",
       "...                  ...               ...  \n",
       "403577        20991231.0               NaN  \n",
       "403578        20991231.0               NaN  \n",
       "403579        20991231.0               NaN  \n",
       "403580        20991231.0               NaN  \n",
       "403581               NaN               NaN  \n",
       "\n",
       "[403582 rows x 16 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af0a699e-1766-4263-9c88-710be10f1e9c",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-02T17:07:46.460828Z",
     "iopub.status.busy": "2023-11-02T17:07:46.460466Z",
     "iopub.status.idle": "2023-11-02T17:14:16.705770Z",
     "shell.execute_reply": "2023-11-02T17:14:16.704790Z",
     "shell.execute_reply.started": "2023-11-02T17:07:46.460801Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m snomed_vocabs\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 3\u001b[0m     target_ids \u001b[38;5;241m=\u001b[39m df_concept_rel\u001b[38;5;241m.\u001b[39mloc[(df_concept_rel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m&\u001b[39m (\u001b[43mdf_concept_rel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelationship_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubsumes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for idx, row in snomed_vocabs.iterrows():\n",
    "    target_ids = df_concept_rel.loc[(df_concept_rel['concept_id_1']==row['concept_id']) & (df_concept_rel['relationship_id']=='Subsumes'), 'concept_id_2'].values\n",
    "    if len(target_ids) == 0:\n",
    "        continue\n",
    "        \n",
    "    cnt += 1\n",
    "    continue\n",
    "    target_ids = np.intersect1d(target_ids, icd10pcs_ids)\n",
    "    \n",
    "    codes = pd.DataFrame({'concept_id':target_ids}).merge(df_concept, on='concept_id')['concept_code'].str[:5].values\n",
    "    asdf\n",
    "    for code in codes:\n",
    "        if code[0] == 0:\n",
    "            # body part\n",
    "            y_p = code[1]+code[3]\n",
    "            y_o = code[2]\n",
    "            y_a = code[4]\n",
    "            break\n",
    "    df_p = pd.concat(df_p, pd.DataFrame({'x': row['concept_name'], 'y': y_p}))\n",
    "    df_o = pd.concat(df_o, pd.DataFrame({'x': row['concept_name'], 'y': y_o}))\n",
    "\n",
    "        \n",
    "    target_ids = df_concept_rel.loc[(df_concept_rel['concept_id_1']==row['concept_id']) & (df_concept_rel['relationship_id']=='Has direct site'), 'concept_id_2'].values\n",
    "    adf\n",
    "    target_ids = df_concept_rel.loc[(df_concept_rel['concept_id_1']==row['concept_id']) & (df_concept_rel['relationship_id']=='Has Method'), 'concept_id_2'].values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0607530a-f947-4c5f-ae8a-e17a3964daca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T17:03:36.155556Z",
     "iopub.status.busy": "2023-11-02T17:03:36.155297Z",
     "iopub.status.idle": "2023-11-02T17:03:36.160324Z",
     "shell.execute_reply": "2023-11-02T17:03:36.159697Z",
     "shell.execute_reply.started": "2023-11-02T17:03:36.155537Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa057d1-b903-4c1c-9fe0-fc4c2898ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2bb7c1-5243-4c43-865b-4532411c5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "922b3c52-0c39-44bc-bccd-b8e1544ebd36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T16:55:50.377683Z",
     "iopub.status.busy": "2023-11-02T16:55:50.377268Z",
     "iopub.status.idle": "2023-11-02T16:55:53.609265Z",
     "shell.execute_reply": "2023-11-02T16:55:53.608407Z",
     "shell.execute_reply.started": "2023-11-02T16:55:50.377647Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id_1</th>\n",
       "      <th>concept_id_2</th>\n",
       "      <th>relationship_id</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25024</th>\n",
       "      <td>36203120</td>\n",
       "      <td>1029151</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20191213</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25036</th>\n",
       "      <td>36203122</td>\n",
       "      <td>1029151</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20191213</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25045</th>\n",
       "      <td>36203134</td>\n",
       "      <td>1029151</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20191213</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25058</th>\n",
       "      <td>36203150</td>\n",
       "      <td>1029151</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20191213</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25066</th>\n",
       "      <td>36203166</td>\n",
       "      <td>1029151</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20191213</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60000766</th>\n",
       "      <td>35608044</td>\n",
       "      <td>4043846</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20180731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60001271</th>\n",
       "      <td>35610430</td>\n",
       "      <td>4044525</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20180731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60003892</th>\n",
       "      <td>35622740</td>\n",
       "      <td>4044190</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20180731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60004300</th>\n",
       "      <td>35624545</td>\n",
       "      <td>4044525</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20180731</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60070378</th>\n",
       "      <td>618698</td>\n",
       "      <td>4044190</td>\n",
       "      <td>Has method</td>\n",
       "      <td>20220128</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287675 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          concept_id_1  concept_id_2 relationship_id  valid_start_date  \\\n",
       "25024         36203120       1029151      Has method          20191213   \n",
       "25036         36203122       1029151      Has method          20191213   \n",
       "25045         36203134       1029151      Has method          20191213   \n",
       "25058         36203150       1029151      Has method          20191213   \n",
       "25066         36203166       1029151      Has method          20191213   \n",
       "...                ...           ...             ...               ...   \n",
       "60000766      35608044       4043846      Has method          20180731   \n",
       "60001271      35610430       4044525      Has method          20180731   \n",
       "60003892      35622740       4044190      Has method          20180731   \n",
       "60004300      35624545       4044525      Has method          20180731   \n",
       "60070378        618698       4044190      Has method          20220128   \n",
       "\n",
       "          valid_end_date  invalid_reason  \n",
       "25024           20991231             NaN  \n",
       "25036           20991231             NaN  \n",
       "25045           20991231             NaN  \n",
       "25058           20991231             NaN  \n",
       "25066           20991231             NaN  \n",
       "...                  ...             ...  \n",
       "60000766        20991231             NaN  \n",
       "60001271        20991231             NaN  \n",
       "60003892        20991231             NaN  \n",
       "60004300        20991231             NaN  \n",
       "60070378        20991231             NaN  \n",
       "\n",
       "[287675 rows x 6 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concept_rel[df_concept_rel['relationship_id']=='Has method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eda21f61-c698-431e-a971-2c580d769b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T16:25:04.401313Z",
     "iopub.status.busy": "2023-11-02T16:25:04.400921Z",
     "iopub.status.idle": "2023-11-02T16:25:07.432069Z",
     "shell.execute_reply": "2023-11-02T16:25:07.431112Z",
     "shell.execute_reply.started": "2023-11-02T16:25:04.401279Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intersect1d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# hysterectomy (concept ID 4127886, concept code 236886002)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#df_concept_rel.loc[(df_concept_rel['concept_id_1']==4127886) & (df_concept_rel['relationship_id']=='Subsumes') & (df_concept_rel['concept_id_2'].isin(icd10pcs_codes)), 'concpet_id_2']\u001b[39;00m\n\u001b[1;32m      4\u001b[0m target_ids \u001b[38;5;241m=\u001b[39m df_concept_rel\u001b[38;5;241m.\u001b[39mloc[(df_concept_rel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m4127886\u001b[39m) \u001b[38;5;241m&\u001b[39m (df_concept_rel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelationship_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSubsumes\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id_2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m----> 5\u001b[0m \u001b[43mintersect1d\u001b[49m(target_ids, icd10pcs_ids)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intersect1d' is not defined"
     ]
    }
   ],
   "source": [
    "# hysterectomy (concept ID 4127886, concept code 236886002)\n",
    "#df_concept_rel.loc[(df_concept_rel['concept_id_1']==4127886) & (df_concept_rel['relationship_id']=='Subsumes') & (df_concept_rel['concept_id_2'].isin(icd10pcs_codes)), 'concpet_id_2']\n",
    "\n",
    "target_ids = df_concept_rel.loc[(df_concept_rel['concept_id_1']==4127886) & (df_concept_rel['relationship_id']=='Subsumes'), 'concept_id_2'].values\n",
    "target_ids = np.intersect1d(target_ids, icd10pcs_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63ff19ca-3b29-49a6-a396-393ac8a9398e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T16:28:04.906937Z",
     "iopub.status.busy": "2023-11-02T16:28:04.906528Z",
     "iopub.status.idle": "2023-11-02T16:28:04.923361Z",
     "shell.execute_reply": "2023-11-02T16:28:04.922682Z",
     "shell.execute_reply.started": "2023-11-02T16:28:04.906900Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concept_id</th>\n",
       "      <th>concept_name</th>\n",
       "      <th>domain_id</th>\n",
       "      <th>vocabulary_id</th>\n",
       "      <th>concept_class_id</th>\n",
       "      <th>standard_concept</th>\n",
       "      <th>concept_code</th>\n",
       "      <th>valid_start_date</th>\n",
       "      <th>valid_end_date</th>\n",
       "      <th>invalid_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45756805</td>\n",
       "      <td>Pediatric Cardiology</td>\n",
       "      <td>Provider</td>\n",
       "      <td>ABMS</td>\n",
       "      <td>Physician Specialty</td>\n",
       "      <td>S</td>\n",
       "      <td>OMOP4821938</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45756804</td>\n",
       "      <td>Pediatric Anesthesiology</td>\n",
       "      <td>Provider</td>\n",
       "      <td>ABMS</td>\n",
       "      <td>Physician Specialty</td>\n",
       "      <td>S</td>\n",
       "      <td>OMOP4821939</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45756803</td>\n",
       "      <td>Pathology-Anatomic / Pathology-Clinical</td>\n",
       "      <td>Provider</td>\n",
       "      <td>ABMS</td>\n",
       "      <td>Physician Specialty</td>\n",
       "      <td>S</td>\n",
       "      <td>OMOP4821940</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45756802</td>\n",
       "      <td>Pathology - Pediatric</td>\n",
       "      <td>Provider</td>\n",
       "      <td>ABMS</td>\n",
       "      <td>Physician Specialty</td>\n",
       "      <td>S</td>\n",
       "      <td>OMOP4821941</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45756801</td>\n",
       "      <td>Pathology - Molecular Genetic</td>\n",
       "      <td>Provider</td>\n",
       "      <td>ABMS</td>\n",
       "      <td>Physician Specialty</td>\n",
       "      <td>S</td>\n",
       "      <td>OMOP4821942</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154804</th>\n",
       "      <td>2213270</td>\n",
       "      <td>Molecular cytogenetics; chromosomal in situ hy...</td>\n",
       "      <td>Measurement</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>S</td>\n",
       "      <td>88272</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154805</th>\n",
       "      <td>45889102</td>\n",
       "      <td>Bone graft, any donor area</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>CPT4 Hierarchy</td>\n",
       "      <td>C</td>\n",
       "      <td>1003752</td>\n",
       "      <td>20141010</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154806</th>\n",
       "      <td>2213271</td>\n",
       "      <td>Molecular cytogenetics; chromosomal in situ hy...</td>\n",
       "      <td>Measurement</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>S</td>\n",
       "      <td>88273</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154807</th>\n",
       "      <td>2213272</td>\n",
       "      <td>Molecular cytogenetics; interphase in situ hyb...</td>\n",
       "      <td>Measurement</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>S</td>\n",
       "      <td>88274</td>\n",
       "      <td>19700101</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9154808</th>\n",
       "      <td>45889100</td>\n",
       "      <td>Excision, coccygeal pressure ulcer, with coccy...</td>\n",
       "      <td>Procedure</td>\n",
       "      <td>CPT4</td>\n",
       "      <td>CPT4 Hierarchy</td>\n",
       "      <td>C</td>\n",
       "      <td>1003535</td>\n",
       "      <td>20141010</td>\n",
       "      <td>20991231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9154809 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         concept_id                                       concept_name  \\\n",
       "0          45756805                               Pediatric Cardiology   \n",
       "1          45756804                           Pediatric Anesthesiology   \n",
       "2          45756803            Pathology-Anatomic / Pathology-Clinical   \n",
       "3          45756802                              Pathology - Pediatric   \n",
       "4          45756801                      Pathology - Molecular Genetic   \n",
       "...             ...                                                ...   \n",
       "9154804     2213270  Molecular cytogenetics; chromosomal in situ hy...   \n",
       "9154805    45889102                         Bone graft, any donor area   \n",
       "9154806     2213271  Molecular cytogenetics; chromosomal in situ hy...   \n",
       "9154807     2213272  Molecular cytogenetics; interphase in situ hyb...   \n",
       "9154808    45889100  Excision, coccygeal pressure ulcer, with coccy...   \n",
       "\n",
       "           domain_id vocabulary_id     concept_class_id standard_concept  \\\n",
       "0           Provider          ABMS  Physician Specialty                S   \n",
       "1           Provider          ABMS  Physician Specialty                S   \n",
       "2           Provider          ABMS  Physician Specialty                S   \n",
       "3           Provider          ABMS  Physician Specialty                S   \n",
       "4           Provider          ABMS  Physician Specialty                S   \n",
       "...              ...           ...                  ...              ...   \n",
       "9154804  Measurement          CPT4                 CPT4                S   \n",
       "9154805    Procedure          CPT4       CPT4 Hierarchy                C   \n",
       "9154806  Measurement          CPT4                 CPT4                S   \n",
       "9154807  Measurement          CPT4                 CPT4                S   \n",
       "9154808    Procedure          CPT4       CPT4 Hierarchy                C   \n",
       "\n",
       "        concept_code  valid_start_date  valid_end_date invalid_reason  \n",
       "0        OMOP4821938          19700101        20991231            NaN  \n",
       "1        OMOP4821939          19700101        20991231            NaN  \n",
       "2        OMOP4821940          19700101        20991231            NaN  \n",
       "3        OMOP4821941          19700101        20991231            NaN  \n",
       "4        OMOP4821942          19700101        20991231            NaN  \n",
       "...              ...               ...             ...            ...  \n",
       "9154804        88272          19700101        20991231            NaN  \n",
       "9154805      1003752          20141010        20991231            NaN  \n",
       "9154806        88273          19700101        20991231            NaN  \n",
       "9154807        88274          19700101        20991231            NaN  \n",
       "9154808      1003535          20141010        20991231            NaN  \n",
       "\n",
       "[9154809 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18b35bb8-458b-49a1-93d2-ea7e51dd0b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-02T16:29:00.347741Z",
     "iopub.status.busy": "2023-11-02T16:29:00.347342Z",
     "iopub.status.idle": "2023-11-02T16:29:03.229447Z",
     "shell.execute_reply": "2023-11-02T16:29:03.228618Z",
     "shell.execute_reply.started": "2023-11-02T16:29:00.347707Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0UB90', '0UB90', '0UB93', '0UB93', '0UB97', '0UB97', '0UB98',\n",
       "       '0UB98', '10T23', '10T27'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = pd.DataFrame({'concept_id':target_ids}).merge(df_concept, on='concept_id')['concept_code'].str[:5].values\n",
    "codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488c2f3-9f0d-47f1-9820-309f05637fdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "76303b87-e18f-4647-8504-45fac845a39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T06:10:44.841504Z",
     "iopub.status.busy": "2023-10-30T06:10:44.840304Z",
     "iopub.status.idle": "2023-10-30T06:10:44.861010Z",
     "shell.execute_reply": "2023-10-30T06:10:44.860200Z",
     "shell.execute_reply.started": "2023-10-30T06:10:44.841439Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Procedure Code Category</th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>Code Status</th>\n",
       "      <th>src</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>opid</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>a</th>\n",
       "      <th>opname</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04B00ZZ</td>\n",
       "      <td>Excision of Abdominal Aorta, Open Approach</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>BB</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04B04ZZ</td>\n",
       "      <td>Excision of Abdominal Aorta, Percutaneous Endo...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>BB</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R007Z</td>\n",
       "      <td>Replacement of Abdominal Aorta with Autologous...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>RR</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R00JZ</td>\n",
       "      <td>Replacement of Abdominal Aorta with Synthetic ...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>RR</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R00KZ</td>\n",
       "      <td>Replacement of Abdominal Aorta with Nonautolog...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>RR</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85252</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Introduction of Gilteritinib Antineoplastic in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mimic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85253</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>New Technology, Physiological Systems, Measure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mimic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85254</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Measurement of Infection, Whole Blood Nucleic ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mimic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85255</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>New Technology, Extracorporeal, Introduction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mimic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Extracorporeal Introduction of Endothelial Dam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mimic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455699 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Procedure Code Category     code  \\\n",
       "0                         AAA  04B00ZZ   \n",
       "1                         AAA  04B04ZZ   \n",
       "2                         AAA  04R007Z   \n",
       "3                         AAA  04R00JZ   \n",
       "4                         AAA  04R00KZ   \n",
       "...                       ...      ...   \n",
       "85252                     NaN     None   \n",
       "85253                     NaN     None   \n",
       "85254                     NaN     None   \n",
       "85255                     NaN     None   \n",
       "85256                     NaN     None   \n",
       "\n",
       "                                                    name Code Status    src  \\\n",
       "0             Excision of Abdominal Aorta, Open Approach   No change    cdc   \n",
       "1      Excision of Abdominal Aorta, Percutaneous Endo...   No change    cdc   \n",
       "2      Replacement of Abdominal Aorta with Autologous...   No change    cdc   \n",
       "3      Replacement of Abdominal Aorta with Synthetic ...   No change    cdc   \n",
       "4      Replacement of Abdominal Aorta with Nonautolog...   No change    cdc   \n",
       "...                                                  ...         ...    ...   \n",
       "85252  Introduction of Gilteritinib Antineoplastic in...         NaN  mimic   \n",
       "85253  New Technology, Physiological Systems, Measure...         NaN  mimic   \n",
       "85254  Measurement of Infection, Whole Blood Nucleic ...         NaN  mimic   \n",
       "85255       New Technology, Extracorporeal, Introduction         NaN  mimic   \n",
       "85256  Extracorporeal Introduction of Endothelial Dam...         NaN  mimic   \n",
       "\n",
       "         0    2 opid    p    o    a opname  icd_version  \n",
       "0      NaN  NaN  NaN   40   BB   00    NaN          NaN  \n",
       "1      NaN  NaN  NaN   40   BB   44    NaN          NaN  \n",
       "2      NaN  NaN  NaN   40   RR   00    NaN          NaN  \n",
       "3      NaN  NaN  NaN   40   RR   00    NaN          NaN  \n",
       "4      NaN  NaN  NaN   40   RR   00    NaN          NaN  \n",
       "...    ...  ...  ...  ...  ...  ...    ...          ...  \n",
       "85252  NaN  NaN  NaN  NaN  NaN  NaN    NaN         10.0  \n",
       "85253  NaN  NaN  NaN  NaN  NaN  NaN    NaN         10.0  \n",
       "85254  NaN  NaN  NaN  NaN  NaN  NaN    NaN         10.0  \n",
       "85255  NaN  NaN  NaN  NaN  NaN  NaN    NaN         10.0  \n",
       "85256  NaN  NaN  NaN  NaN  NaN  NaN    NaN         10.0  \n",
       "\n",
       "[455699 rows x 13 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e195d7b-0647-41ba-a6bc-c1ccd2497103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:06:27.021345Z",
     "iopub.status.busy": "2023-10-30T05:06:27.020989Z",
     "iopub.status.idle": "2023-10-30T05:06:27.034809Z",
     "shell.execute_reply": "2023-10-30T05:06:27.034264Z",
     "shell.execute_reply.started": "2023-10-30T05:06:27.021309Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>name</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>10</td>\n",
       "      <td>Central Nervous System and Cranial Nerves, Bypass</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0016070</td>\n",
       "      <td>10</td>\n",
       "      <td>Bypass Cerebral Ventricle to Nasopharynx with ...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0016071</td>\n",
       "      <td>10</td>\n",
       "      <td>Bypass Cerebral Ventricle to Mastoid Sinus wit...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0016072</td>\n",
       "      <td>10</td>\n",
       "      <td>Bypass Cerebral Ventricle to Atrium with Autol...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0016073</td>\n",
       "      <td>10</td>\n",
       "      <td>Bypass Cerebral Ventricle to Blood Vessel with...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85252</th>\n",
       "      <td>XW0DXV5</td>\n",
       "      <td>10</td>\n",
       "      <td>Introduction of Gilteritinib Antineoplastic in...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85253</th>\n",
       "      <td>XXE</td>\n",
       "      <td>10</td>\n",
       "      <td>New Technology, Physiological Systems, Measure...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85254</th>\n",
       "      <td>XXE5XM5</td>\n",
       "      <td>10</td>\n",
       "      <td>Measurement of Infection, Whole Blood Nucleic ...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85255</th>\n",
       "      <td>XY0</td>\n",
       "      <td>10</td>\n",
       "      <td>New Technology, Extracorporeal, Introduction</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85256</th>\n",
       "      <td>XY0VX83</td>\n",
       "      <td>10</td>\n",
       "      <td>Extracorporeal Introduction of Endothelial Dam...</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81369 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          code  icd_version  \\\n",
       "4          001           10   \n",
       "12     0016070           10   \n",
       "13     0016071           10   \n",
       "14     0016072           10   \n",
       "15     0016073           10   \n",
       "...        ...          ...   \n",
       "85252  XW0DXV5           10   \n",
       "85253      XXE           10   \n",
       "85254  XXE5XM5           10   \n",
       "85255      XY0           10   \n",
       "85256  XY0VX83           10   \n",
       "\n",
       "                                                    name    src  \n",
       "4      Central Nervous System and Cranial Nerves, Bypass  mimic  \n",
       "12     Bypass Cerebral Ventricle to Nasopharynx with ...  mimic  \n",
       "13     Bypass Cerebral Ventricle to Mastoid Sinus wit...  mimic  \n",
       "14     Bypass Cerebral Ventricle to Atrium with Autol...  mimic  \n",
       "15     Bypass Cerebral Ventricle to Blood Vessel with...  mimic  \n",
       "...                                                  ...    ...  \n",
       "85252  Introduction of Gilteritinib Antineoplastic in...  mimic  \n",
       "85253  New Technology, Physiological Systems, Measure...  mimic  \n",
       "85254  Measurement of Infection, Whole Blood Nucleic ...  mimic  \n",
       "85255       New Technology, Extracorporeal, Introduction  mimic  \n",
       "85256  Extracorporeal Introduction of Endothelial Dam...  mimic  \n",
       "\n",
       "[81369 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a02f3cd-68c5-4ffe-8cfd-ba0ab1763f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:51:53.847918Z",
     "iopub.status.busy": "2023-10-30T05:51:53.847321Z",
     "iopub.status.idle": "2023-10-30T05:51:53.890998Z",
     "shell.execute_reply": "2023-10-30T05:51:53.890246Z",
     "shell.execute_reply.started": "2023-10-30T05:51:53.847881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 70631, '1': 314, '2': 871, '3': 1482, '4': 421, '5': 54, '6': 57, '7': 101, '8': 79, '9': 91, 'B': 3036, 'C': 502, 'D': 2075, 'F': 1394, 'G': 42, 'H': 66, 'X': 153}\n"
     ]
    }
   ],
   "source": [
    "my_list = df4['code'].str[0].values\n",
    "element_counts = {}\n",
    "for item in my_list:\n",
    "    if item in element_counts:\n",
    "        element_counts[item] += 1\n",
    "    else:\n",
    "        element_counts[item] = 1\n",
    "\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74232566-9dd5-4ab3-8b6d-4efdd12f5171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:38:51.880806Z",
     "iopub.status.busy": "2023-10-30T05:38:51.880327Z",
     "iopub.status.idle": "2023-10-30T05:38:51.893681Z",
     "shell.execute_reply": "2023-10-30T05:38:51.892876Z",
     "shell.execute_reply.started": "2023-10-30T05:38:51.880771Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opid</th>\n",
       "      <th>p</th>\n",
       "      <th>o</th>\n",
       "      <th>a</th>\n",
       "      <th>opname</th>\n",
       "      <th>name</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>190617045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Salpingo-oophorectomy ( bilateral / multiport ...</td>\n",
       "      <td>Salpingo-oophorectomy ( bilateral / multiport ...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200715065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Salpingo-oophorectomy ( left / single port tot...</td>\n",
       "      <td>Salpingo-oophorectomy ( left / single port tot...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190306113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Ovarian cystectomy ( bilateral / single port t...</td>\n",
       "      <td>Ovarian cystectomy ( bilateral / single port t...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181022121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Ovarian cystectomy ( right / multiport total l...</td>\n",
       "      <td>Ovarian cystectomy ( right / multiport total l...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201120073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lobectomy ( LUL / thoracotomy / with mediastin...</td>\n",
       "      <td>Lobectomy ( LUL / thoracotomy / with mediastin...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286210</th>\n",
       "      <td>110902018</td>\n",
       "      <td>YY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Amputation, 5th toe, Lt.</td>\n",
       "      <td>Amputation, 5th toe, Lt.</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286211</th>\n",
       "      <td>110701008</td>\n",
       "      <td>YY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Amputation of toe, foot, 5th , Lt. prn&gt;4th toe...</td>\n",
       "      <td>Amputation of toe, foot, 5th , Lt. prn&gt;4th toe...</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286212</th>\n",
       "      <td>121207059</td>\n",
       "      <td>YY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Amputation of toe, 5th toe, Lt.</td>\n",
       "      <td>Amputation of toe, 5th toe, Lt.</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286213</th>\n",
       "      <td>110527015</td>\n",
       "      <td>YY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Amputation of toe 5th toe. Lt.</td>\n",
       "      <td>Amputation of toe 5th toe. Lt.</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286214</th>\n",
       "      <td>121010008</td>\n",
       "      <td>YY</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Amputation of toe, 5th, Lt.</td>\n",
       "      <td>Amputation of toe, 5th, Lt.</td>\n",
       "      <td>snuh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>286215 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             opid    p    o    a  \\\n",
       "0       190617045  NaN  NaN    4   \n",
       "1       200715065  NaN  NaN    4   \n",
       "2       190306113  NaN  NaN    4   \n",
       "3       181022121  NaN  NaN    4   \n",
       "4       201120073  NaN  NaN  NaN   \n",
       "...           ...  ...  ...  ...   \n",
       "286210  110902018   YY    6    0   \n",
       "286211  110701008   YY    6    0   \n",
       "286212  121207059   YY    6    0   \n",
       "286213  110527015   YY    6    0   \n",
       "286214  121010008   YY    6    0   \n",
       "\n",
       "                                                   opname  \\\n",
       "0       Salpingo-oophorectomy ( bilateral / multiport ...   \n",
       "1       Salpingo-oophorectomy ( left / single port tot...   \n",
       "2       Ovarian cystectomy ( bilateral / single port t...   \n",
       "3       Ovarian cystectomy ( right / multiport total l...   \n",
       "4       Lobectomy ( LUL / thoracotomy / with mediastin...   \n",
       "...                                                   ...   \n",
       "286210                           Amputation, 5th toe, Lt.   \n",
       "286211  Amputation of toe, foot, 5th , Lt. prn>4th toe...   \n",
       "286212                    Amputation of toe, 5th toe, Lt.   \n",
       "286213                     Amputation of toe 5th toe. Lt.   \n",
       "286214                        Amputation of toe, 5th, Lt.   \n",
       "\n",
       "                                                     name   src  \n",
       "0       Salpingo-oophorectomy ( bilateral / multiport ...  snuh  \n",
       "1       Salpingo-oophorectomy ( left / single port tot...  snuh  \n",
       "2       Ovarian cystectomy ( bilateral / single port t...  snuh  \n",
       "3       Ovarian cystectomy ( right / multiport total l...  snuh  \n",
       "4       Lobectomy ( LUL / thoracotomy / with mediastin...  snuh  \n",
       "...                                                   ...   ...  \n",
       "286210                           Amputation, 5th toe, Lt.  snuh  \n",
       "286211  Amputation of toe, foot, 5th , Lt. prn>4th toe...  snuh  \n",
       "286212                    Amputation of toe, 5th toe, Lt.  snuh  \n",
       "286213                     Amputation of toe 5th toe. Lt.  snuh  \n",
       "286214                        Amputation of toe, 5th, Lt.  snuh  \n",
       "\n",
       "[286215 rows x 7 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "74ea8643-f77c-4164-9446-3a8cca5e9e41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:09:27.303889Z",
     "iopub.status.busy": "2023-10-30T05:09:27.303511Z",
     "iopub.status.idle": "2023-10-30T05:09:27.366836Z",
     "shell.execute_reply": "2023-10-30T05:09:27.366251Z",
     "shell.execute_reply.started": "2023-10-30T05:09:27.303854Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8993, 79122, 108294, 81369)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1['code'].unique()), len(df2['code'].unique()), len(df3['opname'].unique()), len(df4['code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b198622-2e2b-43a9-9b23-a17d08ee2c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T04:13:17.362386Z",
     "iopub.status.busy": "2023-10-30T04:13:17.362011Z",
     "iopub.status.idle": "2023-10-30T04:13:17.375833Z",
     "shell.execute_reply": "2023-10-30T04:13:17.375323Z",
     "shell.execute_reply.started": "2023-10-30T04:13:17.362351Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>code</th>\n",
       "      <th>2</th>\n",
       "      <th>name</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001</td>\n",
       "      <td>001</td>\n",
       "      <td>0</td>\n",
       "      <td>Central Nervous System and Cranial Nerves, Bypass</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002</td>\n",
       "      <td>0016070</td>\n",
       "      <td>1</td>\n",
       "      <td>Bypass Cereb Vent to Nasophar with Autol Sub, ...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00003</td>\n",
       "      <td>0016071</td>\n",
       "      <td>1</td>\n",
       "      <td>Bypass Cereb Vent to Mastoid Sinus w Autol Sub...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00004</td>\n",
       "      <td>0016072</td>\n",
       "      <td>1</td>\n",
       "      <td>Bypass Cereb Vent to Atrium with Autol Sub, Op...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00005</td>\n",
       "      <td>0016073</td>\n",
       "      <td>1</td>\n",
       "      <td>Bypass Cereb Vent to Blood Vess w Autol Sub, Open</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79117</th>\n",
       "      <td>79118</td>\n",
       "      <td>XXE97U7</td>\n",
       "      <td>1</td>\n",
       "      <td>Measurement of Nasophrn Fluid SARS-CoV-2 PCR, ...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79118</th>\n",
       "      <td>79119</td>\n",
       "      <td>XXEBXQ6</td>\n",
       "      <td>1</td>\n",
       "      <td>Measure of Infect, Lwr Resp Fld Microb Detect,...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79119</th>\n",
       "      <td>79120</td>\n",
       "      <td>XY0</td>\n",
       "      <td>0</td>\n",
       "      <td>New Technology, Extracorporeal, Introduction</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79120</th>\n",
       "      <td>79121</td>\n",
       "      <td>XY0VX83</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduce Endoth Dmg Inhib Vn Grft New Tech 3</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79121</th>\n",
       "      <td>79122</td>\n",
       "      <td>XY0YX37</td>\n",
       "      <td>1</td>\n",
       "      <td>Extracorporeal Introduction of Nafamostat, New...</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79122 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     code  2                                               name  \\\n",
       "0      00001      001  0  Central Nervous System and Cranial Nerves, Bypass   \n",
       "1      00002  0016070  1  Bypass Cereb Vent to Nasophar with Autol Sub, ...   \n",
       "2      00003  0016071  1  Bypass Cereb Vent to Mastoid Sinus w Autol Sub...   \n",
       "3      00004  0016072  1  Bypass Cereb Vent to Atrium with Autol Sub, Op...   \n",
       "4      00005  0016073  1  Bypass Cereb Vent to Blood Vess w Autol Sub, Open   \n",
       "...      ...      ... ..                                                ...   \n",
       "79117  79118  XXE97U7  1  Measurement of Nasophrn Fluid SARS-CoV-2 PCR, ...   \n",
       "79118  79119  XXEBXQ6  1  Measure of Infect, Lwr Resp Fld Microb Detect,...   \n",
       "79119  79120      XY0  0       New Technology, Extracorporeal, Introduction   \n",
       "79120  79121  XY0VX83  1      Introduce Endoth Dmg Inhib Vn Grft New Tech 3   \n",
       "79121  79122  XY0YX37  1  Extracorporeal Introduction of Nafamostat, New...   \n",
       "\n",
       "       src  \n",
       "0      cms  \n",
       "1      cms  \n",
       "2      cms  \n",
       "3      cms  \n",
       "4      cms  \n",
       "...    ...  \n",
       "79117  cms  \n",
       "79118  cms  \n",
       "79119  cms  \n",
       "79120  cms  \n",
       "79121  cms  \n",
       "\n",
       "[79122 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "801dc9c4-e03b-45f6-9378-38f8f2c4a9e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:04:32.156170Z",
     "iopub.status.busy": "2023-10-30T05:04:32.155765Z",
     "iopub.status.idle": "2023-10-30T05:04:32.168635Z",
     "shell.execute_reply": "2023-10-30T05:04:32.168155Z",
     "shell.execute_reply.started": "2023-10-30T05:04:32.156137Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Procedure Code Category</th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "      <th>Code Status</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04B00ZZ</td>\n",
       "      <td>Excision of Abdominal Aorta, Open Approach</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04B04ZZ</td>\n",
       "      <td>Excision of Abdominal Aorta, Percutaneous Endo...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R007Z</td>\n",
       "      <td>Replacement of Abdominal Aorta with Autologous...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R00JZ</td>\n",
       "      <td>Replacement of Abdominal Aorta with Synthetic ...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAA</td>\n",
       "      <td>04R00KZ</td>\n",
       "      <td>Replacement of Abdominal Aorta with Nonautolog...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>XLAP</td>\n",
       "      <td>0WWJ40Z</td>\n",
       "      <td>Revision of Drainage Device in Pelvic Cavity, ...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>XLAP</td>\n",
       "      <td>0WWJ41Z</td>\n",
       "      <td>Revision of Radioactive Element in Pelvic Cavi...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8990</th>\n",
       "      <td>XLAP</td>\n",
       "      <td>0WWJ43Z</td>\n",
       "      <td>Revision of Infusion Device in Pelvic Cavity, ...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>XLAP</td>\n",
       "      <td>0WWJ4JZ</td>\n",
       "      <td>Revision of Synthetic Substitute in Pelvic Cav...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>XLAP</td>\n",
       "      <td>0WWJ4YZ</td>\n",
       "      <td>Revision of Other Device in Pelvic Cavity, Per...</td>\n",
       "      <td>No change</td>\n",
       "      <td>cdc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8993 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Procedure Code Category      code  \\\n",
       "0                        AAA  04B00ZZ    \n",
       "1                        AAA  04B04ZZ    \n",
       "2                        AAA  04R007Z    \n",
       "3                        AAA  04R00JZ    \n",
       "4                        AAA  04R00KZ    \n",
       "...                      ...       ...   \n",
       "8988                    XLAP   0WWJ40Z   \n",
       "8989                    XLAP   0WWJ41Z   \n",
       "8990                    XLAP   0WWJ43Z   \n",
       "8991                    XLAP   0WWJ4JZ   \n",
       "8992                    XLAP   0WWJ4YZ   \n",
       "\n",
       "                                                   name Code Status  src  \n",
       "0            Excision of Abdominal Aorta, Open Approach   No change  cdc  \n",
       "1     Excision of Abdominal Aorta, Percutaneous Endo...   No change  cdc  \n",
       "2     Replacement of Abdominal Aorta with Autologous...   No change  cdc  \n",
       "3     Replacement of Abdominal Aorta with Synthetic ...   No change  cdc  \n",
       "4     Replacement of Abdominal Aorta with Nonautolog...   No change  cdc  \n",
       "...                                                 ...         ...  ...  \n",
       "8988  Revision of Drainage Device in Pelvic Cavity, ...   No change  cdc  \n",
       "8989  Revision of Radioactive Element in Pelvic Cavi...   No change  cdc  \n",
       "8990  Revision of Infusion Device in Pelvic Cavity, ...   No change  cdc  \n",
       "8991  Revision of Synthetic Substitute in Pelvic Cav...   No change  cdc  \n",
       "8992  Revision of Other Device in Pelvic Cavity, Per...   No change  cdc  \n",
       "\n",
       "[8993 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1f9bc3bf-18e6-4989-9c54-cc5f466ba952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:11:52.160317Z",
     "iopub.status.busy": "2023-10-30T05:11:52.159962Z",
     "iopub.status.idle": "2023-10-30T05:11:52.175362Z",
     "shell.execute_reply": "2023-10-30T05:11:52.174829Z",
     "shell.execute_reply.started": "2023-10-30T05:11:52.160282Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>name</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70041</th>\n",
       "      <td>0Y6Y0Z2</td>\n",
       "      <td>10</td>\n",
       "      <td>Detachment at Left 5th Toe, Mid, Open Approach</td>\n",
       "      <td>mimic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code  icd_version                                            name  \\\n",
       "70041  0Y6Y0Z2           10  Detachment at Left 5th Toe, Mid, Open Approach   \n",
       "\n",
       "         src  \n",
       "70041  mimic  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4[df4['code']=='0Y6Y0Z2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47648f80-7710-45a4-8eca-d06b61cb1e7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T05:11:58.141816Z",
     "iopub.status.busy": "2023-10-30T05:11:58.141447Z",
     "iopub.status.idle": "2023-10-30T05:11:58.160235Z",
     "shell.execute_reply": "2023-10-30T05:11:58.159660Z",
     "shell.execute_reply.started": "2023-10-30T05:11:58.141781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>code</th>\n",
       "      <th>2</th>\n",
       "      <th>name</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67397</th>\n",
       "      <td>67398</td>\n",
       "      <td>0Y6Y0Z2</td>\n",
       "      <td>1</td>\n",
       "      <td>Detachment at Left 5th Toe, Mid, Open Approach</td>\n",
       "      <td>cms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     code  2                                            name  src\n",
       "67397  67398  0Y6Y0Z2  1  Detachment at Left 5th Toe, Mid, Open Approach  cms"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['code']=='0Y6Y0Z2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb0d6d-89ea-40c6-b91e-898959efb1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "body part -> 1,3\n",
    "surgery type --> 2\n",
    "approach --> 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9fc0d1-b9bf-46c1-8786-476783947f0b",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b8ccf06-c313-41e1-bac1-d8aabb86655b",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-10-30T07:03:00.076798Z",
     "iopub.status.busy": "2023-10-30T07:03:00.075886Z",
     "iopub.status.idle": "2023-10-30T07:03:09.117733Z",
     "shell.execute_reply": "2023-10-30T07:03:09.116437Z",
     "shell.execute_reply.started": "2023-10-30T07:03:00.076754Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/anaconda-3-2020.02/envs/hskim/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "     |████████████████████████████████| 7.7 MB 608 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Collecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "     |████████████████████████████████| 3.8 MB 15.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: filelock in /home/hskim1/.local/lib/python3.8/site-packages (from transformers) (3.12.4)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 16.9 MB/s            \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
      "     |████████████████████████████████| 301 kB 17.2 MB/s            \n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "     |████████████████████████████████| 166 kB 15.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/hskim1/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "     |████████████████████████████████| 295 kB 16.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hskim1/.local/lib/python3.8/site-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.25.8)\n",
      "Installing collected packages: fsspec, huggingface-hub, tokenizers, safetensors, transformers\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/hskim1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed fsspec-2023.10.0 huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550c3c21-db24-4635-9815-6319ae021a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T02:04:40.338847Z",
     "iopub.status.busy": "2023-11-01T02:04:40.338347Z",
     "iopub.status.idle": "2023-11-01T02:04:50.513359Z",
     "shell.execute_reply": "2023-11-01T02:04:50.512468Z",
     "shell.execute_reply.started": "2023-11-01T02:04:40.338809Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'icd10pcs_mapping/Tokenizer/tokenizer_x.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m maxlen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(e) \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m x)  \u001b[38;5;66;03m# fit for max len\u001b[39;00m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mpreprocessing\u001b[38;5;241m.\u001b[39msequence\u001b[38;5;241m.\u001b[39mpad_sequences(x, maxlen\u001b[38;5;241m=\u001b[39mmaxlen)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minput_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/tokenizer_x.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mwrite(t_x\u001b[38;5;241m.\u001b[39mto_json())\n\u001b[1;32m     16\u001b[0m asd\n\u001b[1;32m     17\u001b[0m prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/transformer_res\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda-3-2020.02/envs/hskim/lib/python3.8/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'icd10pcs_mapping/Tokenizer/tokenizer_x.json'"
     ]
    }
   ],
   "source": [
    "input_path = 'icd10pcs_mapping/Tokenizer'\n",
    "\n",
    "# shuffling\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "x = np.copy(df['name'].values)\n",
    "\n",
    "# process x\n",
    "vocab_size = 4000\n",
    "t_x = Tokenizer(vocab_size)\n",
    "t_x.fit_on_texts(x)\n",
    "x = t_x.texts_to_sequences(x)\n",
    "maxlen = max(len(e) for e in x)  # fit for max len\n",
    "x = keras.preprocessing.sequence.pad_sequences(x, maxlen=maxlen)\n",
    "open(f'{input_path}/tokenizer_x.json', \"wt\").write(t_x.to_json())\n",
    "\n",
    "prefix = f'{input_path}/transformer_res'\n",
    "for target in ('p', 'o', 'a'):\n",
    "    opath = f'{prefix}_{target}.csv'\n",
    "    if os.path.exists(opath):\n",
    "        continue\n",
    "\n",
    "    y = np.copy(df[target].values) # body part is consistent within a specific body system\n",
    "\n",
    "    t_y = Tokenizer()\n",
    "    valid_mask = pd.notnull(y)\n",
    "    t_y.fit_on_texts(y[valid_mask])\n",
    "    y[valid_mask] = np.array(t_y.texts_to_sequences(y[valid_mask])).flatten() - 1\n",
    "    open(f'{input_path}/tokenizer_y_{target}.json', \"wt\").write(t_y.to_json())\n",
    "\n",
    "    # train, val, test set\n",
    "    valid_mask = df[target].notnull()\n",
    "    tune_mask = valid_mask & (df['src'] == 'snuh')  # non-snuh -> snuh \n",
    "    pre_mask = valid_mask & ~tune_mask\n",
    "\n",
    "    # model structure\n",
    "    embed_dim = 64  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    droprate = 0.2\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    out = inp\n",
    "    out = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)(out)\n",
    "    out = TransformerBlock(embed_dim, num_heads, ff_dim, droprate)(out)\n",
    "    out = layers.GlobalAveragePooling1D()(out)\n",
    "    out = layers.Dropout(droprate)(out)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    out = layers.Dropout(droprate)(out)\n",
    "    out = layers.Dense(len(t_y.word_index), activation=\"softmax\")(out)\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # # bio clinical bert (pretrained model)\n",
    "    # from transformers import TFAutoModelForSequenceClassification\n",
    "    # model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(t_p.word_index), from_pt=True)\n",
    "\n",
    "    weight_path = f'{input_path}/weights_{target}.h5'\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # pre-trian\n",
    "    print(f'pretraining {target}...')\n",
    "    y_train_pre = y[pre_mask].astype(int)\n",
    "    model.fit(x[pre_mask], y_train_pre,\n",
    "            batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_split=0.1,\n",
    "            callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True),\n",
    "                        EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')])\n",
    "    model.load_weights(weight_path)  # reload the best model\n",
    "\n",
    "    # fine tunning\n",
    "    print(f'fine tuning {target}...')\n",
    "    weight_path = f'{input_path}/tuned_weights_{target}.h5'\n",
    "    y_train_tune = y[tune_mask].astype(int)\n",
    "    model.fit(x[tune_mask], y_train_tune,\n",
    "            batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_split=0.1,\n",
    "            callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True),\n",
    "                        EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')])\n",
    "    model.load_weights(weight_path)  # reload the best model\n",
    "    open(f'{input_path}/model_{target}.json', \"wt\").write(model.to_json())\n",
    "\n",
    "    pred = model.predict(x)\n",
    "    df['pred'] = pd.Series(t_y.sequences_to_texts(np.argmax(pred, axis=1)[...,None] + 1)).str.upper()\n",
    "    df['conf'] = pred.max(axis=1)\n",
    "    df['matched'] = (df['pred'] == df[target]).astype(int)\n",
    "\n",
    "    # save the results for snuh\n",
    "    df[df['src'] == 'snuh'].drop(columns='src').sort_values(by='opid').to_csv(opath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# merge\n",
    "df_a = pd.read_csv(f'{prefix}_a.csv', dtype=str, usecols=['opid', 'pred', 'matched', 'conf'])\n",
    "df_o = pd.read_csv(f'{prefix}_o.csv', dtype=str, usecols=['opid', 'pred', 'matched', 'conf'])\n",
    "df = pd.read_csv(f'{prefix}_p.csv', dtype=str)\n",
    "df = df.merge(df_a, how='left', on='opid', suffixes=('', '_a'))\n",
    "df = df.merge(df_o, how='left', on='opid', suffixes=('', '_o'))\n",
    "df.rename(columns={'pred':'pred_p', 'matched':'matched_p'}, inplace=True)\n",
    "df['code_pred'] = '0'\n",
    "df.loc[df['name'].str.contains('cesarian'), 'code_pred'] = '1'\n",
    "df['code_pred'] += df['pred_p'].str[0] + df['pred_o'] + df['pred_p'].str[1] + df['pred_a']\n",
    "df.to_csv(f'{prefix}.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cb7d20-7c97-4026-bddd-f64c7d72599c",
   "metadata": {},
   "source": [
    "### mover conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534f13e5-4bc2-4bc4-b94b-bd3802441e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T06:08:42.808082Z",
     "iopub.status.busy": "2023-11-17T06:08:42.807683Z",
     "iopub.status.idle": "2023-11-17T06:18:12.268584Z",
     "shell.execute_reply": "2023-11-17T06:18:12.267766Z",
     "shell.execute_reply.started": "2023-11-17T06:08:42.808047Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:08:59.783177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22321 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:c2:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretraining p...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 15:09:02.981941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-17 15:09:03.207307: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x281f7370 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-17 15:09:03.207368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-11-17 15:09:03.327215: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-17 15:09:03.558827: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2023-11-17 15:09:03.713113: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-17 15:09:03.818741: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/516 [==============================] - ETA: 0s - loss: 4.0406 - accuracy: 0.2354\n",
      "Epoch 1: val_loss improved from inf to 0.49146, saving model to icd10pcs_mapping/Tokenizer/weights_p.h5\n",
      "516/516 [==============================] - 20s 28ms/step - loss: 4.0406 - accuracy: 0.2354 - val_loss: 0.4915 - val_accuracy: 0.8728\n",
      "Epoch 2/100\n",
      " 14/516 [..............................] - ETA: 4s - loss: 0.8319 - accuracy: 0.7720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskim1/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/516 [============================>.] - ETA: 0s - loss: 0.3621 - accuracy: 0.8942\n",
      "Epoch 2: val_loss improved from 0.49146 to 0.04978, saving model to icd10pcs_mapping/Tokenizer/weights_p.h5\n",
      "516/516 [==============================] - 5s 11ms/step - loss: 0.3606 - accuracy: 0.8946 - val_loss: 0.0498 - val_accuracy: 0.9815\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9601\n",
      "Epoch 3: val_loss improved from 0.04978 to 0.01618, saving model to icd10pcs_mapping/Tokenizer/weights_p.h5\n",
      "516/516 [==============================] - 5s 10ms/step - loss: 0.1232 - accuracy: 0.9601 - val_loss: 0.0162 - val_accuracy: 0.9950\n",
      "Epoch 4/100\n",
      "511/516 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9749\n",
      "Epoch 4: val_loss improved from 0.01618 to 0.01138, saving model to icd10pcs_mapping/Tokenizer/weights_p.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 0.0774 - accuracy: 0.9749 - val_loss: 0.0114 - val_accuracy: 0.9969\n",
      "Epoch 5/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.9823\n",
      "Epoch 5: val_loss improved from 0.01138 to 0.00313, saving model to icd10pcs_mapping/Tokenizer/weights_p.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 0.0553 - accuracy: 0.9823 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 6/100\n",
      "510/516 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9854\n",
      "Epoch 6: val_loss did not improve from 0.00313\n",
      "516/516 [==============================] - 4s 8ms/step - loss: 0.0455 - accuracy: 0.9855 - val_loss: 0.0058 - val_accuracy: 0.9988\n",
      "Epoch 7/100\n",
      "514/516 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9868\n",
      "Epoch 7: val_loss did not improve from 0.00313\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.0053 - val_accuracy: 0.9988\n",
      "fine tuning p...\n",
      "Epoch 1/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 1.1356 - accuracy: 0.7852\n",
      "Epoch 1: val_loss improved from inf to 0.49727, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 29s 29ms/step - loss: 1.1356 - accuracy: 0.7852 - val_loss: 0.4973 - val_accuracy: 0.8911\n",
      "Epoch 2/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.5146 - accuracy: 0.8780\n",
      "Epoch 2: val_loss improved from 0.49727 to 0.40974, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.5146 - accuracy: 0.8780 - val_loss: 0.4097 - val_accuracy: 0.9025\n",
      "Epoch 3/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8935\n",
      "Epoch 3: val_loss improved from 0.40974 to 0.38552, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.4377 - accuracy: 0.8935 - val_loss: 0.3855 - val_accuracy: 0.9076\n",
      "Epoch 4/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.3942 - accuracy: 0.9023\n",
      "Epoch 4: val_loss improved from 0.38552 to 0.35965, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.3942 - accuracy: 0.9023 - val_loss: 0.3596 - val_accuracy: 0.9122\n",
      "Epoch 5/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.9084\n",
      "Epoch 5: val_loss improved from 0.35965 to 0.33728, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.3634 - accuracy: 0.9084 - val_loss: 0.3373 - val_accuracy: 0.9200\n",
      "Epoch 6/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.3414 - accuracy: 0.9127\n",
      "Epoch 6: val_loss improved from 0.33728 to 0.33198, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.3414 - accuracy: 0.9127 - val_loss: 0.3320 - val_accuracy: 0.9211\n",
      "Epoch 7/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.3239 - accuracy: 0.9160\n",
      "Epoch 7: val_loss improved from 0.33198 to 0.33052, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 10s 10ms/step - loss: 0.3239 - accuracy: 0.9160 - val_loss: 0.3305 - val_accuracy: 0.9234\n",
      "Epoch 8/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.9184\n",
      "Epoch 8: val_loss improved from 0.33052 to 0.32655, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 10ms/step - loss: 0.3100 - accuracy: 0.9184 - val_loss: 0.3265 - val_accuracy: 0.9227\n",
      "Epoch 9/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.9210\n",
      "Epoch 9: val_loss improved from 0.32655 to 0.32103, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_p.h5\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.2977 - accuracy: 0.9210 - val_loss: 0.3210 - val_accuracy: 0.9250\n",
      "Epoch 10/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.9227\n",
      "Epoch 10: val_loss did not improve from 0.32103\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.2886 - accuracy: 0.9227 - val_loss: 0.3227 - val_accuracy: 0.9265\n",
      "Epoch 11/100\n",
      "972/972 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.9250\n",
      "Epoch 11: val_loss did not improve from 0.32103\n",
      "972/972 [==============================] - 9s 9ms/step - loss: 0.2773 - accuracy: 0.9250 - val_loss: 0.3247 - val_accuracy: 0.9266\n",
      "14241/14241 [==============================] - 31s 2ms/step\n",
      "598/598 [==============================] - 1s 2ms/step\n",
      "pretraining o...\n",
      "Epoch 1/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8587\n",
      "Epoch 1: val_loss improved from inf to 0.00131, saving model to icd10pcs_mapping/Tokenizer/weights_o.h5\n",
      "516/516 [==============================] - 14s 22ms/step - loss: 0.5126 - accuracy: 0.8587 - val_loss: 0.0013 - val_accuracy: 0.9995\n",
      "Epoch 2/100\n",
      " 14/516 [..............................] - ETA: 4s - loss: 0.0024 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskim1/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515/516 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 2: val_loss improved from 0.00131 to 0.00007, saving model to icd10pcs_mapping/Tokenizer/weights_o.h5\n",
      "516/516 [==============================] - 5s 10ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 7.4080e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 4.8997e-04 - accuracy: 1.0000\n",
      "Epoch 3: val_loss improved from 0.00007 to 0.00007, saving model to icd10pcs_mapping/Tokenizer/weights_o.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 4.8997e-04 - accuracy: 1.0000 - val_loss: 7.3679e-05 - val_accuracy: 0.9999\n",
      "Epoch 4/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 2.5765e-04 - accuracy: 1.0000\n",
      "Epoch 4: val_loss improved from 0.00007 to 0.00002, saving model to icd10pcs_mapping/Tokenizer/weights_o.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 2.5765e-04 - accuracy: 1.0000 - val_loss: 1.8357e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "514/516 [============================>.] - ETA: 0s - loss: 2.2723e-04 - accuracy: 1.0000\n",
      "Epoch 5: val_loss did not improve from 0.00002\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 2.2682e-04 - accuracy: 1.0000 - val_loss: 7.6170e-05 - val_accuracy: 0.9999\n",
      "Epoch 6/100\n",
      "512/516 [============================>.] - ETA: 0s - loss: 1.9553e-04 - accuracy: 1.0000\n",
      "Epoch 6: val_loss did not improve from 0.00002\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 1.9483e-04 - accuracy: 1.0000 - val_loss: 4.1982e-04 - val_accuracy: 0.9999\n",
      "fine tuning o...\n",
      "Epoch 1/100\n",
      "977/978 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.8688\n",
      "Epoch 1: val_loss improved from inf to 0.27713, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_o.h5\n",
      "978/978 [==============================] - 22s 22ms/step - loss: 0.5124 - accuracy: 0.8689 - val_loss: 0.2771 - val_accuracy: 0.9232\n",
      "Epoch 2/100\n",
      "976/978 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.9259\n",
      "Epoch 2: val_loss improved from 0.27713 to 0.24432, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_o.h5\n",
      "978/978 [==============================] - 9s 9ms/step - loss: 0.2625 - accuracy: 0.9259 - val_loss: 0.2443 - val_accuracy: 0.9325\n",
      "Epoch 3/100\n",
      "975/978 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.9337\n",
      "Epoch 3: val_loss improved from 0.24432 to 0.22500, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_o.h5\n",
      "978/978 [==============================] - 9s 9ms/step - loss: 0.2319 - accuracy: 0.9338 - val_loss: 0.2250 - val_accuracy: 0.9365\n",
      "Epoch 4/100\n",
      "974/978 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9381\n",
      "Epoch 4: val_loss improved from 0.22500 to 0.22428, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_o.h5\n",
      "978/978 [==============================] - 9s 9ms/step - loss: 0.2150 - accuracy: 0.9381 - val_loss: 0.2243 - val_accuracy: 0.9389\n",
      "Epoch 5/100\n",
      "974/978 [============================>.] - ETA: 0s - loss: 0.2034 - accuracy: 0.9403\n",
      "Epoch 5: val_loss improved from 0.22428 to 0.21722, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_o.h5\n",
      "978/978 [==============================] - 9s 9ms/step - loss: 0.2033 - accuracy: 0.9403 - val_loss: 0.2172 - val_accuracy: 0.9386\n",
      "Epoch 6/100\n",
      "972/978 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 0.9428\n",
      "Epoch 6: val_loss did not improve from 0.21722\n",
      "978/978 [==============================] - 9s 9ms/step - loss: 0.1928 - accuracy: 0.9428 - val_loss: 0.2186 - val_accuracy: 0.9379\n",
      "Epoch 7/100\n",
      "978/978 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9444\n",
      "Epoch 7: val_loss did not improve from 0.21722\n",
      "978/978 [==============================] - 8s 9ms/step - loss: 0.1858 - accuracy: 0.9444 - val_loss: 0.2175 - val_accuracy: 0.9395\n",
      "14241/14241 [==============================] - 31s 2ms/step\n",
      "598/598 [==============================] - 1s 2ms/step\n",
      "pretraining a...\n",
      "Epoch 1/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9106\n",
      "Epoch 1: val_loss improved from inf to 0.00022, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 15s 22ms/step - loss: 0.2302 - accuracy: 0.9106 - val_loss: 2.1720e-04 - val_accuracy: 0.9999\n",
      "Epoch 2/100\n",
      " 14/516 [..............................] - ETA: 4s - loss: 0.0014 - accuracy: 0.9997  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskim1/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "513/516 [============================>.] - ETA: 0s - loss: 3.5841e-04 - accuracy: 0.9999\n",
      "Epoch 2: val_loss improved from 0.00022 to 0.00001, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 3.5676e-04 - accuracy: 0.9999 - val_loss: 1.2532e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 8.3137e-05 - accuracy: 1.0000\n",
      "Epoch 3: val_loss improved from 0.00001 to 0.00000, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 8.3137e-05 - accuracy: 1.0000 - val_loss: 3.4716e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "515/516 [============================>.] - ETA: 0s - loss: 2.9432e-04 - accuracy: 0.9999\n",
      "Epoch 4: val_loss did not improve from 0.00000\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 2.9496e-04 - accuracy: 0.9999 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 5/100\n",
      "512/516 [============================>.] - ETA: 0s - loss: 6.7201e-04 - accuracy: 0.9998\n",
      "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 4s 8ms/step - loss: 6.6707e-04 - accuracy: 0.9998 - val_loss: 8.1401e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 1.3859e-05 - accuracy: 1.0000\n",
      "Epoch 6: val_loss improved from 0.00000 to 0.00000, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 4s 8ms/step - loss: 1.3859e-05 - accuracy: 1.0000 - val_loss: 2.1407e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "512/516 [============================>.] - ETA: 0s - loss: 7.2389e-06 - accuracy: 1.0000\n",
      "Epoch 7: val_loss improved from 0.00000 to 0.00000, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 4s 8ms/step - loss: 7.2295e-06 - accuracy: 1.0000 - val_loss: 1.1878e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "513/516 [============================>.] - ETA: 0s - loss: 6.0360e-06 - accuracy: 1.0000\n",
      "Epoch 8: val_loss improved from 0.00000 to 0.00000, saving model to icd10pcs_mapping/Tokenizer/weights_a.h5\n",
      "516/516 [==============================] - 4s 8ms/step - loss: 6.0208e-06 - accuracy: 1.0000 - val_loss: 4.9370e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "514/516 [============================>.] - ETA: 0s - loss: 7.9835e-06 - accuracy: 1.0000\n",
      "Epoch 9: val_loss did not improve from 0.00000\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 7.9631e-06 - accuracy: 1.0000 - val_loss: 5.9454e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "516/516 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9961\n",
      "Epoch 10: val_loss did not improve from 0.00000\n",
      "516/516 [==============================] - 5s 9ms/step - loss: 0.0220 - accuracy: 0.9961 - val_loss: 0.0012 - val_accuracy: 0.9997\n",
      "fine tuning a...\n",
      "Epoch 1/100\n",
      "989/989 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.8984\n",
      "Epoch 1: val_loss improved from inf to 0.13534, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_a.h5\n",
      "989/989 [==============================] - 21s 21ms/step - loss: 0.4112 - accuracy: 0.8984 - val_loss: 0.1353 - val_accuracy: 0.9638\n",
      "Epoch 2/100\n",
      "989/989 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.9696\n",
      "Epoch 2: val_loss improved from 0.13534 to 0.09643, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_a.h5\n",
      "989/989 [==============================] - 11s 11ms/step - loss: 0.1107 - accuracy: 0.9696 - val_loss: 0.0964 - val_accuracy: 0.9734\n",
      "Epoch 3/100\n",
      "985/989 [============================>.] - ETA: 0s - loss: 0.0868 - accuracy: 0.9755\n",
      "Epoch 3: val_loss improved from 0.09643 to 0.08457, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_a.h5\n",
      "989/989 [==============================] - 9s 9ms/step - loss: 0.0868 - accuracy: 0.9755 - val_loss: 0.0846 - val_accuracy: 0.9759\n",
      "Epoch 4/100\n",
      "989/989 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9781\n",
      "Epoch 4: val_loss did not improve from 0.08457\n",
      "989/989 [==============================] - 9s 9ms/step - loss: 0.0751 - accuracy: 0.9781 - val_loss: 0.0894 - val_accuracy: 0.9761\n",
      "Epoch 5/100\n",
      "989/989 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 0.9799\n",
      "Epoch 5: val_loss improved from 0.08457 to 0.07603, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_a.h5\n",
      "989/989 [==============================] - 9s 9ms/step - loss: 0.0678 - accuracy: 0.9799 - val_loss: 0.0760 - val_accuracy: 0.9789\n",
      "Epoch 6/100\n",
      "983/989 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9813\n",
      "Epoch 6: val_loss improved from 0.07603 to 0.07130, saving model to icd10pcs_mapping/Tokenizer/tuned_weights_a.h5\n",
      "989/989 [==============================] - 8s 9ms/step - loss: 0.0627 - accuracy: 0.9813 - val_loss: 0.0713 - val_accuracy: 0.9804\n",
      "Epoch 7/100\n",
      "988/989 [============================>.] - ETA: 0s - loss: 0.0577 - accuracy: 0.9825\n",
      "Epoch 7: val_loss did not improve from 0.07130\n",
      "989/989 [==============================] - 8s 8ms/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.0760 - val_accuracy: 0.9804\n",
      "Epoch 8/100\n",
      "984/989 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9835\n",
      "Epoch 8: val_loss did not improve from 0.07130\n",
      "989/989 [==============================] - 9s 9ms/step - loss: 0.0545 - accuracy: 0.9835 - val_loss: 0.0743 - val_accuracy: 0.9814\n",
      "14241/14241 [==============================] - 31s 2ms/step\n",
      "598/598 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "input_path = 'icd10pcs_mapping/Tokenizer'\n",
    "\n",
    "# shuffling\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "#df_info = pd.read_csv('mover/EPIC_EMR/patient_information.csv')\n",
    "#df_info['procedure_nm'] = df_info['PRIMARY_PROCEDURE_NM'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "df_info = pd.read_csv('mover/SIS_EMR/patient_information.csv')\n",
    "df_info['procedure_nm'] = df_info['Procedure'].apply(lambda x: x if isinstance(x, str) else '')\n",
    "\n",
    "x = np.copy(df['name'].values)\n",
    "\n",
    "# process x\n",
    "vocab_size = 4000\n",
    "t_x = Tokenizer(vocab_size)\n",
    "t_x.fit_on_texts(x)\n",
    "x = t_x.texts_to_sequences(x)\n",
    "maxlen = max(len(e) for e in x)  # fit for max len\n",
    "x = keras.preprocessing.sequence.pad_sequences(x, maxlen=maxlen)\n",
    "open(f'{input_path}/tokenizer_x.json', \"wt\").write(t_x.to_json())\n",
    "\n",
    "mover_text = np.copy(df_info['procedure_nm'].values)\n",
    "mover_x = t_x.texts_to_sequences(mover_text)\n",
    "mover_x = keras.preprocessing.sequence.pad_sequences(mover_x, maxlen=maxlen)\n",
    "\n",
    "prefix = f'{input_path}/transformer_res'\n",
    "for target in ('p', 'o', 'a'):\n",
    "    opath = f'{prefix}_{target}.csv'\n",
    "    #if os.path.exists(opath):\n",
    "    #    continue\n",
    "\n",
    "    y = np.copy(df[target].values) # body part is consistent within a specific body system\n",
    "\n",
    "    t_y = Tokenizer()\n",
    "    valid_mask = pd.notnull(y)\n",
    "    t_y.fit_on_texts(y[valid_mask])\n",
    "    y[valid_mask] = np.array(t_y.texts_to_sequences(y[valid_mask])).flatten() - 1\n",
    "    open(f'{input_path}/tokenizer_y_{target}.json', \"wt\").write(t_y.to_json())\n",
    "\n",
    "    # train, val, test set\n",
    "    valid_mask = df[target].notnull()\n",
    "    tune_mask = valid_mask & (df['src'] == 'snuh')  # non-snuh -> snuh \n",
    "    pre_mask = valid_mask & ~tune_mask\n",
    "\n",
    "    # model structure\n",
    "    embed_dim = 64  # Embedding size for each token\n",
    "    num_heads = 2  # Number of attention heads\n",
    "    ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
    "    droprate = 0.2\n",
    "    inp = layers.Input(shape=(maxlen,))\n",
    "    out = inp\n",
    "    out = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)(out)\n",
    "    out = TransformerBlock(embed_dim, num_heads, ff_dim, droprate)(out)\n",
    "    out = layers.GlobalAveragePooling1D()(out)\n",
    "    out = layers.Dropout(droprate)(out)\n",
    "    out = layers.Dense(256, activation=\"relu\")(out)\n",
    "    out = layers.Dropout(droprate)(out)\n",
    "    out = layers.Dense(len(t_y.word_index), activation=\"softmax\")(out)\n",
    "    model = keras.Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # # bio clinical bert (pretrained model)\n",
    "    # from transformers import TFAutoModelForSequenceClassification\n",
    "    # model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(t_p.word_index), from_pt=True)\n",
    "\n",
    "    weight_path = f'{input_path}/weights_{target}.h5'\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # pre-trian\n",
    "    print(f'pretraining {target}...')\n",
    "    y_train_pre = y[pre_mask].astype(int)\n",
    "    model.fit(x[pre_mask], y_train_pre,\n",
    "            batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_split=0.1,\n",
    "            callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True),\n",
    "                        EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')])\n",
    "    model.load_weights(weight_path)  # reload the best model\n",
    "\n",
    "    # fine tunning\n",
    "    print(f'fine tuning {target}...')\n",
    "    weight_path = f'{input_path}/tuned_weights_{target}.h5'\n",
    "    y_train_tune = y[tune_mask].astype(int)\n",
    "    model.fit(x[tune_mask], y_train_tune,\n",
    "            batch_size=BATCH_SIZE, epochs=NUM_EPOCH, validation_split=0.1,\n",
    "            callbacks=[ModelCheckpoint(monitor='val_loss', filepath=weight_path, verbose=1, save_best_only=True),\n",
    "                        EarlyStopping(monitor='val_loss', patience=2, verbose=0, mode='auto')])\n",
    "    model.load_weights(weight_path)  # reload the best model\n",
    "    open(f'{input_path}/model_{target}.json', \"wt\").write(model.to_json())\n",
    "\n",
    "    pred = model.predict(x)\n",
    "    df['pred'] = pd.Series(t_y.sequences_to_texts(np.argmax(pred, axis=1)[...,None] + 1)).str.upper()\n",
    "    df['conf'] = pred.max(axis=1)\n",
    "    df['matched'] = (df['pred'] == df[target]).astype(int)\n",
    "\n",
    "    # save the results for snuh\n",
    "    df[df['src'] == 'snuh'].drop(columns='src').sort_values(by='opid').to_csv(opath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # mover\n",
    "    m_pred = model.predict(mover_x)\n",
    "    df_info[f'pred_{target}'] = pd.Series(t_y.sequences_to_texts(np.argmax(m_pred, axis=1)[...,None] + 1)).str.upper()\n",
    "    df_info['conf'] = m_pred.max(axis=1)\n",
    "\n",
    "    # save the results for snuh\n",
    "    df_info.to_csv(f'{prefix}_{target}_mover_sis.csv', index=False, encoding='utf-8-sig')\n",
    "    \n",
    "\n",
    "df_info['code_pred'] = '0'\n",
    "df_info.loc[df_info['procedure_nm'].str.contains('cesarian'), 'code_pred'] = '1'\n",
    "df_info['code_pred'] += df_info['pred_p'].str[0] + df_info['pred_o'] + df_info['pred_p'].str[1] + df_info['pred_a']\n",
    "\n",
    "df_info.to_csv(f'mover/sis_procedure_mapped.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5352320a-4340-4818-8d2f-d8c00e550e12",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa98998-5a50-4b43-b7d5-910403265089",
   "metadata": {},
   "source": [
    "## MOVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b08248b-c709-4600-acad-022135b993e0",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-01T02:11:50.425626Z",
     "iopub.status.busy": "2023-11-01T02:11:50.425185Z",
     "iopub.status.idle": "2023-11-01T02:11:50.835402Z",
     "shell.execute_reply": "2023-11-01T02:11:50.834589Z",
     "shell.execute_reply.started": "2023-11-01T02:11:50.425590Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'MOVER/EPIC_EMR/patient_information.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_info \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMOVER/EPIC_EMR/patient_information.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_info\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MOVER/EPIC_EMR/patient_information.csv'"
     ]
    }
   ],
   "source": [
    "df_info = pd.read_csv('mover/EPIC_EMR/patient_information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66c938a3-773d-4957-aba9-00e1d125b864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-30T11:25:45.448695Z",
     "iopub.status.busy": "2023-10-30T11:25:45.448289Z",
     "iopub.status.idle": "2023-10-30T11:25:45.456523Z",
     "shell.execute_reply": "2023-10-30T11:25:45.455601Z",
     "shell.execute_reply.started": "2023-10-30T11:25:45.448661Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['INSERTION, PUBOVAGINAL SLING, WITH CYSTOSCOPY', 'GI EGD DILATION',\n",
       "       'CRANIECTOMY', ...,\n",
       "       'FOOT AND ANKLE - MASS OR FOREIGN BODY EXCISION',\n",
       "       'CYSTOSCOPY, WITH URETERAL STENT INSERTION',\n",
       "       'INSERTION, PENILE PROSTHESIS'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mover_x = np.copy(df_info['PRIMARY_PROCEDURE_NM'].values)\n",
    "x = t_x.texts_to_sequences(mover_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67f512-e54b-42a5-baf5-1f0578fc48d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664e456a-5eed-4bca-a12f-cc0edc16eb29",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-11-01T01:59:41.674017Z",
     "iopub.status.busy": "2023-11-01T01:59:41.673535Z",
     "iopub.status.idle": "2023-11-01T01:59:41.783688Z",
     "shell.execute_reply": "2023-11-01T01:59:41.782898Z",
     "shell.execute_reply.started": "2023-11-01T01:59:41.673982Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_json:\n\u001b[1;32m      5\u001b[0m     model_json \u001b[38;5;241m=\u001b[39m f_json\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m load_weight_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tuned_weights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(load_weight_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/legacy/model_config.py:125\u001b[0m, in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parses a JSON model configuration string and returns a model instance.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    A Keras model instance (uncompiled).\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m     deserialize_from_json,\n\u001b[1;32m    123\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/layers/serialization.py:299\u001b[0m, in \u001b[0;36mdeserialize_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    293\u001b[0m populate_deserializable_objects()\n\u001b[1;32m    294\u001b[0m config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode_and_deserialize(\n\u001b[1;32m    295\u001b[0m     json_string,\n\u001b[1;32m    296\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    297\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    298\u001b[0m )\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/layers/serialization.py:276\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_legacy_format:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    270\u001b[0m         config,\n\u001b[1;32m    271\u001b[0m         module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    272\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    273\u001b[0m         printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/serialization_lib.py:600\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m    594\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[1;32m    595\u001b[0m                 serialize_with_public_fn(\n\u001b[1;32m    596\u001b[0m                     module_objects[config], config, fn_module_name\n\u001b[1;32m    597\u001b[0m                 ),\n\u001b[1;32m    598\u001b[0m                 custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    599\u001b[0m             )\n\u001b[0;32m--> 600\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserialize_with_public_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_config\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3227\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3219\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3220\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3221\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3222\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3223\u001b[0m )\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3225\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3227\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3231\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3232\u001b[0m     )\n\u001b[1;32m   3233\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/functional.py:1502\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1501\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1503\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1505\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/functional.py:1442\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1438\u001b[0m ):\n\u001b[1;32m   1439\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1440\u001b[0m         input_tensors\n\u001b[1;32m   1441\u001b[0m     )\n\u001b[0;32m-> 1442\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1447\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "part = 'a'\n",
    "with open(f\"{load_path}/model_{part}.json\", 'r') as f_json:\n",
    "    model_json = f_json.read()\n",
    "\n",
    "model = model_from_json(model_json)\n",
    "load_weight_path = f'{load_path}/tuned_weights_{part}.h5'\n",
    "model.load_weights(load_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2061cdc2-4d9d-41d0-bf29-6ceb9b6ff73a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-01T01:58:08.161761Z",
     "iopub.status.busy": "2023-11-01T01:58:08.161291Z",
     "iopub.status.idle": "2023-11-01T01:58:09.366695Z",
     "shell.execute_reply": "2023-11-01T01:58:09.365870Z",
     "shell.execute_reply.started": "2023-11-01T01:58:08.161726Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     t_x1 \u001b[38;5;241m=\u001b[39m f_json\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# load model and tokenizer for body part, surgery type, approach\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m model_a, t_a \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m model_o, t_o \u001b[38;5;241m=\u001b[39m load_model(load_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m model_p, t_p \u001b[38;5;241m=\u001b[39m load_model(load_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(load_path, part)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_json:\n\u001b[1;32m      8\u001b[0m     model_json \u001b[38;5;241m=\u001b[39m f_json\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m load_weight_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mload_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tuned_weights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(load_weight_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/legacy/model_config.py:125\u001b[0m, in \u001b[0;36mmodel_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parses a JSON model configuration string and returns a model instance.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mUsage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    A Keras model instance (uncompiled).\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m     deserialize_from_json,\n\u001b[1;32m    123\u001b[0m )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/layers/serialization.py:299\u001b[0m, in \u001b[0;36mdeserialize_from_json\u001b[0;34m(json_string, custom_objects)\u001b[0m\n\u001b[1;32m    293\u001b[0m populate_deserializable_objects()\n\u001b[1;32m    294\u001b[0m config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode_and_deserialize(\n\u001b[1;32m    295\u001b[0m     json_string,\n\u001b[1;32m    296\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    297\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    298\u001b[0m )\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/layers/serialization.py:276\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_legacy_format:\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    270\u001b[0m         config,\n\u001b[1;32m    271\u001b[0m         module_objects\u001b[38;5;241m=\u001b[39mLOCAL\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    272\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    273\u001b[0m         printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    274\u001b[0m     )\n\u001b[0;32m--> 276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/serialization_lib.py:600\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(module_objects[config], types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m    594\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m deserialize_keras_object(\n\u001b[1;32m    595\u001b[0m                 serialize_with_public_fn(\n\u001b[1;32m    596\u001b[0m                     module_objects[config], config, fn_module_name\n\u001b[1;32m    597\u001b[0m                 ),\n\u001b[1;32m    598\u001b[0m                 custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    599\u001b[0m             )\n\u001b[0;32m--> 600\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mserialize_with_public_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_config\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PLAIN_TYPES):\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/saving/serialization_lib.py:704\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m safe_mode_scope \u001b[38;5;241m=\u001b[39m SafeModeScope(safe_mode)\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m custom_obj_scope, safe_mode_scope:\n\u001b[0;32m--> 704\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     build_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m build_config:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3227\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3219\u001b[0m revivable_as_functional \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3220\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {functional\u001b[38;5;241m.\u001b[39mFunctional, Model}\n\u001b[1;32m   3221\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m==\u001b[39m functional_init_args\n\u001b[1;32m   3222\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (argspec\u001b[38;5;241m.\u001b[39mvarargs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m argspec\u001b[38;5;241m.\u001b[39mvarkw \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3223\u001b[0m )\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m   3225\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[0;32m-> 3227\u001b[0m     inputs, outputs, layers \u001b[38;5;241m=\u001b[39m \u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[1;32m   3229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3230\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   3231\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs, outputs\u001b[38;5;241m=\u001b[39moutputs, name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3232\u001b[0m     )\n\u001b[1;32m   3233\u001b[0m     functional\u001b[38;5;241m.\u001b[39mconnect_ancillary_layers(model, layers)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/functional.py:1502\u001b[0m, in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m layer_nodes:\n\u001b[1;32m   1501\u001b[0m     node_data \u001b[38;5;241m=\u001b[39m layer_nodes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1503\u001b[0m         layer_nodes\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1505\u001b[0m         \u001b[38;5;66;03m# If a node can't be processed, stop processing the\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m         \u001b[38;5;66;03m# nodes of the current layer to maintain node ordering.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/functional.py:1442\u001b[0m, in \u001b[0;36mreconstruct_from_config.<locals>.process_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1436\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_preserve_input_structure_in_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1437\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer\u001b[38;5;241m.\u001b[39m_preserve_input_structure_in_config\n\u001b[1;32m   1438\u001b[0m ):\n\u001b[1;32m   1439\u001b[0m     input_tensors \u001b[38;5;241m=\u001b[39m base_layer_utils\u001b[38;5;241m.\u001b[39munnest_if_single_tensor(\n\u001b[1;32m   1440\u001b[0m         input_tensors\n\u001b[1;32m   1441\u001b[0m     )\n\u001b[0;32m-> 1442\u001b[0m output_tensors \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;66;03m# Update node index map.\u001b[39;00m\n\u001b[1;32m   1445\u001b[0m output_index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(output_tensors)[\n\u001b[1;32m   1446\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1447\u001b[0m ]\u001b[38;5;241m.\u001b[39m_keras_history\u001b[38;5;241m.\u001b[39mnode_index\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "load_path = 'icd10pcs_mapping/Tokenizer'\n",
    "\n",
    "def load_model(load_path, part):\n",
    "    # Load a transformer model\n",
    "    with open(f\"{load_path}/model_{part}.json\", 'r') as f_json:\n",
    "        model_json = f_json.read()\n",
    "\n",
    "    model = model_from_json(model_json)\n",
    "    load_weight_path = f'{load_path}/tuned_weights_{part}.h5'\n",
    "    model.load_weights(load_weight_path)\n",
    "    \n",
    "    # Load a tokenizer\n",
    "    with open(f\"{load_path}/tokenizer_y_{part}.json\", 'r') as f_json:\n",
    "        tokenizer = f_json.read()\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "# Load tokenizer for procedure name\n",
    "with open(f\"{load_path}/tokenizer_x.json\", 'r') as f_json:\n",
    "    t_x1 = f_json.read()\n",
    "\n",
    "# load model and tokenizer for body part, surgery type, approach\n",
    "model_a, t_a = load_model(load_path, 'a')\n",
    "model_o, t_o = load_model(load_path, 'o')\n",
    "model_p, t_p = load_model(load_path, 'p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e81a49-a525-40e6-a4d6-284ee5a79c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9a595-537f-44a2-b22c-ef5fe33c96ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hskim",
   "language": "python",
   "name": "hskim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
